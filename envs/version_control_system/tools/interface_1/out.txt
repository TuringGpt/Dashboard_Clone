
import json
import base64
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class CreateBranch(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        repository_id: str,
        branch_name: str,
        source_branch: Optional[str] = None
    ) -> str:
        def generate_id(table: Dict[str, Any]) -> str:
            if not table:
                return "1"
            return str(max(int(k) for k in table.keys()) + 1)
        
        def get_user_from_token(token: str, tokens_data: Dict[str, Any]) -> Optional[str]:
            """Encode token and find associated user_id"""
            try:
                encoded_token = base64.b64encode(token.encode('utf-8')).decode('utf-8')
                for token_info in tokens_data.values():
                    if token_info.get("token_encoded") == encoded_token:
                        return token_info.get("user_id")
                return None
            except:
                return None
        
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        repositories = data.get("repositories", {})
        branches = data.get("branches", {})
        access_tokens = data.get("access_tokens", {})
        repository_collaborators = data.get("repository_collaborators", {})
        organization_members = data.get("organization_members", {})
        
        # Validate access token
        requesting_user_id = get_user_from_token(access_token, access_tokens)
        if not requesting_user_id:
            return json.dumps({
                "success": False,
                "error": "Invalid or expired access token"
            })
        
        # Check if repository exists
        if repository_id not in repositories:
            return json.dumps({
                "success": False,
                "error": f"Repository with ID '{repository_id}' not found"
            })
        
        repository = repositories[repository_id]
        
        # Check if repository is archived
        if repository.get("is_archived", False):
            return json.dumps({
                "success": False,
                "error": "Cannot create branches in an archived repository"
            })
        
        owner_id = repository.get("owner_id")
        owner_type = repository.get("owner_type")
        
        # Check if user has permission to create branches
        has_permission = False
        
        # Check if user is the owner
        if owner_type == "user" and owner_id == requesting_user_id:
            has_permission = True
        
        # Check if user is a collaborator with write or admin access
        if not has_permission:
            for collab in repository_collaborators.values():
                if (collab.get("repository_id") == repository_id and
                    collab.get("user_id") == requesting_user_id and
                    collab.get("permission_level") in ["write", "admin"] and
                    collab.get("status") == "active"):
                    has_permission = True
                    break
        
        # Check if repository is owned by an organization and user is a member
        if not has_permission and owner_type == "organization":
            for membership in organization_members.values():
                if (membership.get("organization_id") == owner_id and
                    membership.get("user_id") == requesting_user_id and
                    membership.get("status") == "active"):
                    has_permission = True
                    break
        
        if not has_permission:
            return json.dumps({
                "success": False,
                "error": "Insufficient permissions. You must have write access to this repository to create branches"
            })
        
        # Check if branch name already exists in this repository
        for branch in branches.values():
            if (branch.get("repository_id") == repository_id and
                branch.get("branch_name") == branch_name):
                return json.dumps({
                    "success": False,
                    "error": f"Branch '{branch_name}' already exists in this repository"
                })
        
        # Find source branch if provided
        source_branch_id = None
        source_commit_sha = None
        
        if source_branch:
            for branch_id, branch in branches.items():
                if (branch.get("repository_id") == repository_id and
                    branch.get("branch_name") == source_branch):
                    source_branch_id = branch_id
                    source_commit_sha = branch.get("commit_sha")
                    break
            
            if not source_branch_id:
                return json.dumps({
                    "success": False,
                    "error": f"Source branch '{source_branch}' not found in this repository"
                })
        else:
            # Try to find default branch as source
            for branch_id, branch in branches.items():
                if (branch.get("repository_id") == repository_id and
                    branch.get("is_default") == True):
                    source_branch_id = branch_id
                    source_commit_sha = branch.get("commit_sha")
                    break
            
            # If no default branch exists, this is the first branch
            # (source_branch_id and source_commit_sha remain None)
        
        timestamp = "2026-01-01T23:59:00"
        new_branch_id = generate_id(branches)
        
        new_branch = {
            "branch_id": new_branch_id,
            "repository_id": repository_id,
            "branch_name": branch_name,
            "commit_sha": source_commit_sha,
            "source_branch": source_branch_id,
            "is_default": False,
            "created_at": timestamp,
            "updated_at": timestamp
        }
        
        branches[new_branch_id] = new_branch
        
        return json.dumps({
            "success": True,
            "branch_id": new_branch_id,
            "branch_data": new_branch
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "create_branch",
                "description": "Creates a new branch in a repository",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "Access token for authentication (required)"
                        },
                        "repository_id": {
                            "type": "string",
                            "description": "Repository ID to create the branch in (required)"
                        },
                        "branch_name": {
                            "type": "string",
                            "description": "Name of the new branch (required)"
                        },
                        "source_branch": {
                            "type": "string",
                            "description": "Name of the source branch to create from (optional, defaults to default branch if it exists)"
                        }
                    },
                    "required": ["access_token", "repository_id", "branch_name"]
                }
            }
        }
import json
import base64
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class CreateOrganization(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        organization_name: str,
        display_name: Optional[str] = None,
        description: Optional[str] = None,
        visibility: Optional[str] = None,
        plan_type: Optional[str] = None
    ) -> str:
        def generate_id(table: Dict[str, Any]) -> str:
            if not table:
                return "1"
            return str(max(int(k) for k in table.keys()) + 1)
        
        def get_user_from_token(token: str, tokens_data: Dict[str, Any]) -> Optional[str]:
            """Encode token and find associated user_id"""
            try:
                encoded_token = base64.b64encode(token.encode('utf-8')).decode('utf-8')
                for token_info in tokens_data.values():
                    if token_info.get("token_encoded") == encoded_token:
                        return token_info.get("user_id")
                return None
            except:
                return None
        
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        organizations = data.get("organizations", {})
        organization_members = data.get("organization_members", {})
        users = data.get("users", {})
        access_tokens = data.get("access_tokens", {})
        
        # Validate access token
        requesting_user_id = get_user_from_token(access_token, access_tokens)
        if not requesting_user_id:
            return json.dumps({
                "success": False,
                "error": "Invalid or expired access token"
            })
        
        # Validate user status
        requesting_user = users.get(requesting_user_id)
        if not requesting_user:
            return json.dumps({
                "success": False,
                "error": "User not found"
            })
        
        if requesting_user.get("status") != "active":
            return json.dumps({
                "success": False,
                "error": "User account is not active"
            })
        
        # Validate visibility if provided
        if visibility and visibility not in ["public", "limited", "private"]:
            return json.dumps({
                "success": False,
                "error": f"Invalid visibility '{visibility}'. Must be 'public', 'limited', or 'private'"
            })
        
        # Validate plan_type if provided
        if plan_type and plan_type not in ["free", "team", "enterprise"]:
            return json.dumps({
                "success": False,
                "error": f"Invalid plan_type '{plan_type}'. Must be 'free', 'team', or 'enterprise'"
            })
        
        # Check for duplicate organization name
        for org in organizations.values():
            if org.get("organization_name") == organization_name:
                return json.dumps({
                    "success": False,
                    "error": f"Organization with name '{organization_name}' already exists"
                })
        
        timestamp = "2026-01-01T23:59:00"
        new_org_id = generate_id(organizations)
        
        new_org = {
            "organization_id": new_org_id,
            "organization_name": organization_name,
            "display_name": display_name,
            "description": description,
            "visibility": visibility if visibility else "private",
            "plan_type": plan_type if plan_type else "free",
            "created_at": timestamp,
            "updated_at": timestamp
        }
        
        organizations[new_org_id] = new_org
        
        # Automatically add the creator as an owner
        membership_id = generate_id(organization_members)
        
        new_membership = {
            "membership_id": membership_id,
            "organization_id": new_org_id,
            "user_id": requesting_user_id,
            "role": "owner",
            "status": "active",
            "joined_at": timestamp
        }
        
        organization_members[membership_id] = new_membership
        
        return json.dumps({
            "success": True,
            "action": "create",
            "organization_id": new_org_id,
            "organization_data": new_org,
            "creator_membership": new_membership
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "create_organization",
                "description": "Creates a new organization. Requires valid access token for authentication",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "Access token for authentication (required)"
                        },
                        "organization_name": {
                            "type": "string",
                            "description": "Name of the organization (required)"
                        },
                        "display_name": {
                            "type": "string",
                            "description": "Display name of the organization (optional)"
                        },
                        "description": {
                            "type": "string",
                            "description": "Organization description (optional)"
                        },
                        "visibility": {
                            "type": "string",
                            "description": "Organization visibility. Allowed values: 'public', 'limited', 'private' (optional, defaults to 'private')",
                            "enum": ["public", "limited", "private"]
                        },
                        "plan_type": {
                            "type": "string",
                            "description": "Plan type. Allowed values: 'free', 'team', 'enterprise' (optional, defaults to 'free')",
                            "enum": ["free", "team", "enterprise"]
                        }
                    },
                    "required": ["access_token", "organization_name"]
                }
            }
        }import json
import base64
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class CreatePullRequest(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        repository_id: str,
        title: str,
        source_branch: str,
        target_branch: str,
        description: Optional[str] = None,
        status: Optional[str] = None
    ) -> str:
        def generate_id(table: Dict[str, Any]) -> str:
            if not table:
                return "1"
            return str(max(int(k) for k in table.keys()) + 1)
        
        def get_user_from_token(token: str, tokens_data: Dict[str, Any]) -> Optional[str]:
            """Encode token and find associated user_id"""
            try:
                encoded_token = base64.b64encode(token.encode('utf-8')).decode('utf-8')
                for token_info in tokens_data.values():
                    if token_info.get("token_encoded") == encoded_token:
                        return token_info.get("user_id")
                return None
            except:
                return None
        
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        repositories = data.get("repositories", {})
        branches = data.get("branches", {})
        pull_requests = data.get("pull_requests", {})
        users = data.get("users", {})
        access_tokens = data.get("access_tokens", {})
        repository_collaborators = data.get("repository_collaborators", {})
        organization_members = data.get("organization_members", {})
        
        # Validate access token
        requesting_user_id = get_user_from_token(access_token, access_tokens)
        if not requesting_user_id:
            return json.dumps({
                "success": False,
                "error": "Invalid or expired access token"
            })
        
        # Author is always the authenticated user
        author_id = requesting_user_id
        
        # Check if repository exists
        if repository_id not in repositories:
            return json.dumps({
                "success": False,
                "error": f"Repository with ID '{repository_id}' not found"
            })
        
        # Check if author exists (should always be true since we got it from token)
        if author_id not in users:
            return json.dumps({
                "success": False,
                "error": f"Authenticated user with ID '{author_id}' not found"
            })
        
        repository = repositories[repository_id]
        owner_id = repository.get("owner_id")
        owner_type = repository.get("owner_type")
        
        # Validate source branch exists
        source_branch_exists = False
        for branch in branches.values():
            if (branch.get("repository_id") == repository_id and 
                branch.get("branch_name") == source_branch):
                source_branch_exists = True
                break
        
        if not source_branch_exists:
            return json.dumps({
                "success": False,
                "error": f"Source branch '{source_branch}' not found in repository"
            })
        
        # Validate target branch exists
        target_branch_exists = False
        for branch in branches.values():
            if (branch.get("repository_id") == repository_id and 
                branch.get("branch_name") == target_branch):
                target_branch_exists = True
                break
        
        if not target_branch_exists:
            return json.dumps({
                "success": False,
                "error": f"Target branch '{target_branch}' not found in repository"
            })
        
        # Validate source and target branches are different
        if source_branch == target_branch:
            return json.dumps({
                "success": False,
                "error": "Source and target branches must be different"
            })
        
        # Check if user has permission to create pull requests
        has_permission = False
        
        # Check if user is the owner
        if owner_type == "user" and owner_id == requesting_user_id:
            has_permission = True
        
        # Check if user is a collaborator with write or admin access
        if not has_permission:
            for collab in repository_collaborators.values():
                if (collab.get("repository_id") == repository_id and
                    collab.get("user_id") == requesting_user_id and
                    collab.get("permission_level") in ["write", "admin"] and
                    collab.get("status") == "active"):
                    has_permission = True
                    break
        
        # Check if repository is owned by an organization and user is a member
        if not has_permission and owner_type == "organization":
            for membership in organization_members.values():
                if (membership.get("organization_id") == owner_id and
                    membership.get("user_id") == requesting_user_id and
                    membership.get("status") == "active"):
                    has_permission = True
                    break
        
        if not has_permission:
            return json.dumps({
                "success": False,
                "error": "Insufficient permissions. You must have write access to this repository to create pull requests"
            })
        
        # Validate status if provided
        if status and status not in ["open", "closed", "merged", "draft"]:
            return json.dumps({
                "success": False,
                "error": f"Invalid status '{status}'. Must be 'open', 'closed', 'merged', or 'draft'"
            })
        
        # Generate pull request number (sequential per repository)
        pr_number = 1
        for pr in pull_requests.values():
            if pr.get("repository_id") == repository_id:
                current_number = pr.get("pull_request_number", 0)
                if current_number >= pr_number:
                    pr_number = current_number + 1
        
        timestamp = "2026-01-01T23:59:00"
        new_pr_id = generate_id(pull_requests)
        
        new_pr = {
            "pull_request_id": new_pr_id,
            "repository_id": repository_id,
            "pull_request_number": pr_number,
            "title": title,
            "description": description,
            "author_id": author_id,
            "source_branch": source_branch,
            "target_branch": target_branch,
            "status": status if status else "open",
            "merged_by": None,
            "merged_at": None,
            "closed_at": None,
            "created_at": timestamp,
            "updated_at": timestamp
        }
        
        pull_requests[new_pr_id] = new_pr
        
        return json.dumps({
            "success": True,
            "pull_request_id": new_pr_id,
            "pull_request_data": new_pr
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "create_pull_request",
                "description": "Creates a new pull request in a repository. The author is automatically set to the authenticated user.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "Access token for authentication (required)"
                        },
                        "repository_id": {
                            "type": "string",
                            "description": "Repository ID (required)"
                        },
                        "title": {
                            "type": "string",
                            "description": "Pull request title (required)"
                        },
                        "source_branch": {
                            "type": "string",
                            "description": "Source branch name (required)"
                        },
                        "target_branch": {
                            "type": "string",
                            "description": "Target branch name (required)"
                        },
                        "description": {
                            "type": "string",
                            "description": "Pull request description (optional)"
                        },
                        "status": {
                            "type": "string",
                            "description": "Pull request status. Allowed values: 'open', 'closed', 'merged', 'draft' (optional, defaults to 'open')",
                            "enum": ["open", "closed", "merged", "draft"]
                        }
                    },
                    "required": ["access_token", "repository_id", "title", "source_branch", "target_branch"]
                }
            }
        }
import json
import base64
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool

class CreateWorkflow(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        repository_id: str,
        workflow_name: str,
        workflow_path: str,
        trigger_event: str,
        status: Optional[str] = 'active'
    ) -> str:
        def generate_id(table: Dict[str, Any]) -> str:
            if not table:
                return "1"
            return str(max(int(k) for k in table.keys()) + 1)

        timestamp = "2026-01-01T23:59:00"

        try:
            encoded_input_token = base64.b64encode(access_token.encode('utf-8')).decode('utf-8')
        except Exception:
            return json.dumps({"error": "Failed to process access token"})

        tokens = data.get("access_tokens", {})
        user_id = None
        
        for token in tokens.values():
            if token.get("token_encoded") == encoded_input_token and token.get("status") == "active":
                if token.get("expires_at") > timestamp:
                    user_id = token.get("user_id")
                    break
        
        if not user_id:
            return json.dumps({"error": "Invalid or expired access token"})

        repositories = data.get("repositories", {})
        if repository_id not in repositories:
            return json.dumps({"error": f"Repository {repository_id} not found"})

        repo = repositories[repository_id]
        
  
        has_permission = False
        
        if repo.get("owner_type") == 'user' and repo.get("owner_id") == user_id:
            has_permission = True
        
        if not has_permission and repo.get("owner_type") == 'organization':
            org_members = data.get("organization_members", {})
            for member in org_members.values():
                if (member.get("organization_id") == repo.get("owner_id") and 
                    member.get("user_id") == user_id and 
                    member.get("status") == "active" and 
                    member.get("role") == "owner"):
                    has_permission = True
                    break

        if not has_permission:
            collaborators = data.get("repository_collaborators", {})
            for collab in collaborators.values():
                if (collab.get("repository_id") == repository_id and 
                    collab.get("user_id") == user_id and 
                    collab.get("status") == "active" and 
                    collab.get("permission_level") in ['write', 'admin']):
                    has_permission = True
                    break
        
        if not has_permission:
            return json.dumps({"error": "User does not have permission to create workflows in this repository"})

        # QA Correction: Update valid trigger events
        valid_events = ['push', 'pull_request', 'schedule']
        if trigger_event not in valid_events:
            return json.dumps({"error": f"Invalid trigger_event. Must be one of: {', '.join(valid_events)}"})

        # QA Correction: Update valid status values to match 'user_status' enum
        valid_statuses = ['active', 'suspended', 'deleted']
        if status not in valid_statuses:
            return json.dumps({"error": f"Invalid status. Must be one of: {', '.join(valid_statuses)}"})

        # Create Workflow
        workflows = data.get("workflows", {})
        new_id = generate_id(workflows)
        new_workflow = {
            "workflow_id": new_id,
            "repository_id": repository_id,
            "workflow_name": workflow_name,
            "workflow_path": workflow_path,
            "trigger_event": trigger_event,
            "status": status,
            "created_at": timestamp,
            "updated_at": timestamp
        }

        workflows[new_id] = new_workflow
        return json.dumps(new_workflow)

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "create_workflow",
                "description": "Creates a new CI/CD workflow for a repository, enforcing permission checks.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "The access token for authentication."
                        },
                        "repository_id": {
                            "type": "string",
                            "description": "The ID of the repository."
                        },
                        "workflow_name": {
                            "type": "string",
                            "description": "The name of the workflow."
                        },
                        "workflow_path": {
                            "type": "string",
                            "description": "The path to the workflow file (e.g., .github/workflows/main.yml)."
                        },
                        "trigger_event": {
                            "type": "string",
                            "description": "The event that triggers the workflow. Allowed values: 'push', 'pull_request', 'schedule'.",
                            "enum": ["push", "pull_request", "schedule"]
                        },
                        "status": {
                            "type": "string",
                            "description": "The initial status of the workflow. Allowed values: 'active', 'suspended', 'deleted'. Default is 'active' (optional)",
                            "enum": ["active", "suspended", "deleted"]
                        }
                    },
                    "required": ["access_token", "repository_id", "workflow_name", "workflow_path", "trigger_event"]
                }
            }
        }import json
import base64
from typing import Any, Dict
from tau_bench.envs.tool import Tool

class DeleteComment(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        comment_id: str
    ) -> str:
        timestamp = "2026-01-01T23:59:00"
        try:
            encoded_input_token = base64.b64encode(access_token.encode('utf-8')).decode('utf-8')
        except Exception:
            return json.dumps({"error": "Failed to process access token"})

        tokens = data.get("access_tokens", {})
        valid_token = False
        for token in tokens.values():
            if token.get("token_encoded") == encoded_input_token and token.get("status") == "active":
                if token.get("expires_at") > timestamp:
                    valid_token = True
                    break
        
        if not valid_token:
            return json.dumps({"error": "Invalid or expired access token"})

        comments = data.get("comments", {})

        if comment_id not in comments:
            return json.dumps({"error": f"Comment {comment_id} not found"})

        deleted_comment = comments.pop(comment_id)
        return json.dumps(deleted_comment)

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "delete_comment",
                "description": "Deletes a comment by ID.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "The access token for authentication."
                        },
                        "comment_id": {
                            "type": "string",
                            "description": "The ID of the comment to delete."
                        }
                    },
                    "required": ["access_token", "comment_id"]
                }
            }
        }import json
import base64
import hashlib
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class DeleteFile(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        repository_id: str,
        branch_id: str,
        file_id: str,
        commit_message: Optional[str] = None
    ) -> str:
        def generate_id(table: Dict[str, Any]) -> str:
            if not table:
                return "1"
            return str(max(int(k) for k in table.keys()) + 1)

        def generate_commit_sha(repo_id: str, branch_id: str, index: int) -> str:
            seed = f"{repo_id}:{branch_id}:{index}"
            return hashlib.sha1(seed.encode()).hexdigest()

        def get_user_from_token(token: str, tokens_data: Dict[str, Any]) -> Optional[str]:
            """Encode token and find associated user_id"""
            try:
                encoded_token = base64.b64encode(token.encode("utf-8")).decode("utf-8")
                for token_info in tokens_data.values():
                    if token_info.get("token_encoded") == encoded_token:
                        return token_info.get("user_id")
                return None
            except Exception:
                return None

        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })

        repositories = data.get("repositories", {})
        branches = data.get("branches", {})
        files = data.get("files", {})
        commits = data.get("commits", {})
        access_tokens = data.get("access_tokens", {})
        repository_collaborators = data.get("repository_collaborators", {})
        organization_members = data.get("organization_members", {})
        users = data.get("users", {})

        # Validate access token
        requesting_user_id = get_user_from_token(access_token, access_tokens)
        if not requesting_user_id:
            return json.dumps({
                "success": False,
                "error": "Invalid or expired access token"
            })

        author_id = requesting_user_id

        # Validate repository
        if repository_id not in repositories:
            return json.dumps({
                "success": False,
                "error": f"Repository with ID '{repository_id}' not found"
            })

        # Validate branch
        if branch_id not in branches:
            return json.dumps({
                "success": False,
                "error": f"Branch with ID '{branch_id}' not found"
            })

        branch = branches[branch_id]

        if branch.get("repository_id") != repository_id:
            return json.dumps({
                "success": False,
                "error": f"Branch with ID '{branch_id}' does not belong to repository '{repository_id}'"
            })

        # Validate file
        if file_id not in files:
            return json.dumps({
                "success": False,
                "error": f"File with ID '{file_id}' not found"
            })

        file_obj = files[file_id]

        if file_obj.get("repository_id") != repository_id:
            return json.dumps({
                "success": False,
                "error": f"File does not belong to repository '{repository_id}'"
            })

        if file_obj.get("branch_id") != branch_id:
            return json.dumps({
                "success": False,
                "error": f"File does not belong to branch '{branch_id}'"
            })

        if author_id not in users:
            return json.dumps({
                "success": False,
                "error": f"Authenticated user with ID '{author_id}' not found"
            })

        repository = repositories[repository_id]
        owner_id = repository.get("owner_id")
        owner_type = repository.get("owner_type")

        # Permission check
        has_permission = False

        if owner_type == "user" and owner_id == requesting_user_id:
            has_permission = True

        if not has_permission:
            for collab in repository_collaborators.values():
                if (
                    collab.get("repository_id") == repository_id and
                    collab.get("user_id") == requesting_user_id and
                    collab.get("permission_level") in ["write", "admin"] and
                    collab.get("status") == "active"
                ):
                    has_permission = True
                    break

        if not has_permission and owner_type == "organization":
            for membership in organization_members.values():
                if (
                    membership.get("organization_id") == owner_id and
                    membership.get("user_id") == requesting_user_id and
                    membership.get("status") == "active"
                ):
                    has_permission = True
                    break

        if not has_permission:
            return json.dumps({
                "success": False,
                "error": "Insufficient permissions. You must have write access to this repository to delete files"
            })

        # Parent commit resolution
        parent_commit_sha = branch.get("commit_sha")
        parent_commit_id = None

        if parent_commit_sha:
            for cid, commit in commits.items():
                if commit.get("commit_sha") == parent_commit_sha:
                    parent_commit_id = cid
                    break

        # Create commit
        timestamp = "2026-01-01T23:59:00"
        new_commit_id = generate_id(commits)

        new_commit_sha = generate_commit_sha(
            repository_id,
            branch_id,
            int(new_commit_id)
        )

        file_name = file_obj.get("file_name")

        new_commit = {
            "commit_id": new_commit_id,
            "repository_id": repository_id,
            "commit_sha": new_commit_sha,
            "author_id": author_id,
            "committer_id": author_id,
            "message": commit_message if commit_message else f"Delete {file_name}",
            "parent_commit_id": parent_commit_id,
            "committed_at": timestamp,
            "created_at": timestamp
        }

        commits[new_commit_id] = new_commit

        # Update branch pointer
        branch["commit_sha"] = new_commit_sha
        branch["updated_at"] = timestamp

        # Delete file
        deleted_file = files.pop(file_id)

        return json.dumps({
            "success": True,
            "file_id": file_id,
            "commit_id": new_commit_id,
            "deleted_file": deleted_file,
            "commit_data": new_commit
        })

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "delete_file",
                "description": (
                    "Deletes a file from a repository branch. The author is automatically set to the authenticated user."
                ),
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "Access token for authentication (required)"
                        },
                        "repository_id": {
                            "type": "string",
                            "description": "Repository ID containing the file (required)"
                        },
                        "branch_id": {
                            "type": "string",
                            "description": "Branch ID to delete the file from (required)"
                        },
                        "file_id": {
                            "type": "string",
                            "description": "File ID to delete (required)"
                        },
                        "commit_message": {
                            "type": "string",
                            "description": "Commit message for the deletion (optional)"
                        }
                    },
                    "required": ["access_token", "repository_id", "branch_id", "file_id"]
                }
            }
        }

import json
import base64
from typing import Any, Dict
from tau_bench.envs.tool import Tool

class DeleteIssue(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        issue_id: str
    ) -> str:
        timestamp = "2026-01-01T23:59:00"
       
        try:
            encoded_input_token = base64.b64encode(access_token.encode('utf-8')).decode('utf-8')
        except Exception:
            return json.dumps({"error": "Failed to process access token"})

        tokens = data.get("access_tokens", {})
        valid_token = False
        for token in tokens.values():
            if token.get("token_encoded") == encoded_input_token and token.get("status") == "active":
                if token.get("expires_at") > timestamp:
                    valid_token = True
                    break
        
        if not valid_token:
            return json.dumps({"error": "Invalid or expired access token"})

        issues = data.get("issues", {})

        if issue_id not in issues:
            return json.dumps({"error": f"Issue {issue_id} not found"})

        deleted_issue = issues.pop(issue_id)
        return json.dumps(deleted_issue)

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "delete_issue",
                "description": "Deletes an issue by ID.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "The access token for authentication."
                        },
                        "issue_id": {
                            "type": "string",
                            "description": "The ID of the issue to delete."
                        }
                    },
                    "required": ["access_token", "issue_id"]
                }
            }
        }import json
import base64
from typing import Any, Dict
from tau_bench.envs.tool import Tool

class DeleteRelease(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        release_id: str
    ) -> str:
        timestamp = "2026-01-01T23:59:00"

        try:
            encoded_input_token = base64.b64encode(access_token.encode('utf-8')).decode('utf-8')
        except Exception:
            return json.dumps({"error": "Failed to process access token"})

        tokens = data.get("access_tokens", {})
        valid_token = False
        for token in tokens.values():
            if token.get("token_encoded") == encoded_input_token and token.get("status") == "active":
                if token.get("expires_at") > timestamp:
                    valid_token = True
                    break
        
        if not valid_token:
            return json.dumps({"error": "Invalid or expired access token"})

        releases = data.get("releases", {})

        if release_id not in releases:
            return json.dumps({"error": f"Release {release_id} not found"})

        deleted_release = releases.pop(release_id)
        return json.dumps(deleted_release)

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "delete_release",
                "description": "Deletes a release by its ID.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "The access token for authentication."
                        },
                        "release_id": {
                            "type": "string",
                            "description": "The ID of the release to delete."
                        }
                    },
                    "required": ["access_token", "release_id"]
                }
            }
        }
import json
import base64
from typing import Any, Dict
from tau_bench.envs.tool import Tool

class DeleteWorkflow(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        workflow_id: str
    ) -> str:
        timestamp = "2026-01-01T23:59:00"

        try:
            encoded_input_token = base64.b64encode(access_token.encode('utf-8')).decode('utf-8')
        except Exception:
            return json.dumps({"error": "Failed to process access token"})

        tokens = data.get("access_tokens", {})
        valid_token = False
        for token in tokens.values():
            if token.get("token_encoded") == encoded_input_token and token.get("status") == "active":
                if token.get("expires_at") > timestamp:
                    valid_token = True
                    break
        
        if not valid_token:
            return json.dumps({"error": "Invalid or expired access token"})

        workflows = data.get("workflows", {})

        if workflow_id not in workflows:
            return json.dumps({"error": f"Workflow {workflow_id} not found"})

        deleted_workflow = workflows.pop(workflow_id)
        # successful deletion message
        deleted_workflow["message"] = f"Workflow {workflow_id} has been successfully deleted."
        return json.dumps(deleted_workflow)

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "delete_workflow",
                "description": "Permanently deletes a workflow record.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "The access token for authentication."
                        },
                        "workflow_id": {
                            "type": "string",
                            "description": "The ID of the workflow to delete."
                        }
                    },
                    "required": ["access_token", "workflow_id"]
                }
            }
        }import json
import base64
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class EraseBranch(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        repository_id: str,
        branch_name: str
    ) -> str:
        def get_user_from_token(token: str, tokens_data: Dict[str, Any]) -> Optional[str]:
            """Encode token and find associated user_id"""
            try:
                encoded_token = base64.b64encode(token.encode('utf-8')).decode('utf-8')
                for token_info in tokens_data.values():
                    if token_info.get("token_encoded") == encoded_token:
                        return token_info.get("user_id")
                return None
            except:
                return None
        
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        repositories = data.get("repositories", {})
        branches = data.get("branches", {})
        access_tokens = data.get("access_tokens", {})
        repository_collaborators = data.get("repository_collaborators", {})
        organization_members = data.get("organization_members", {})
        
        # Validate access token
        requesting_user_id = get_user_from_token(access_token, access_tokens)
        if not requesting_user_id:
            return json.dumps({
                "success": False,
                "error": "Invalid or expired access token"
            })
        
        # Check if repository exists
        if repository_id not in repositories:
            return json.dumps({
                "success": False,
                "error": f"Repository with ID '{repository_id}' not found"
            })
        
        repository = repositories[repository_id]
        
        # Check if repository is archived
        if repository.get("is_archived", False):
            return json.dumps({
                "success": False,
                "error": "Cannot delete branches from an archived repository"
            })
        
        owner_id = repository.get("owner_id")
        owner_type = repository.get("owner_type")
        
        # Check if user has permission to delete branches
        has_permission = False
        
        # Check if user is the owner
        if owner_type == "user" and owner_id == requesting_user_id:
            has_permission = True
        
        # Check if user is a collaborator with write or admin access
        if not has_permission:
            for collab in repository_collaborators.values():
                if (collab.get("repository_id") == repository_id and
                    collab.get("user_id") == requesting_user_id and
                    collab.get("permission_level") in ["write", "admin"] and
                    collab.get("status") == "active"):
                    has_permission = True
                    break
        
        # Check if repository is owned by an organization and user is a member
        if not has_permission and owner_type == "organization":
            for membership in organization_members.values():
                if (membership.get("organization_id") == owner_id and
                    membership.get("user_id") == requesting_user_id and
                    membership.get("status") == "active"):
                    has_permission = True
                    break
        
        if not has_permission:
            return json.dumps({
                "success": False,
                "error": "Insufficient permissions. You must have write access to this repository to delete branches"
            })
        
        # Find the branch to delete
        branch_to_delete_id = None
        branch_to_delete = None
        
        for branch_id, branch in branches.items():
            if (branch.get("repository_id") == repository_id and
                branch.get("branch_name") == branch_name):
                branch_to_delete_id = branch_id
                branch_to_delete = branch
                break
        
        if not branch_to_delete_id:
            return json.dumps({
                "success": False,
                "error": f"Branch '{branch_name}' not found in this repository"
            })
        
        # Prevent deletion of default branch
        if branch_to_delete.get("is_default"):
            return json.dumps({
                "success": False,
                "error": f"Cannot delete default branch '{branch_name}'"
            })
        
        # Delete the branch
        del branches[branch_to_delete_id]
        
        return json.dumps({
            "success": True,
            "branch_id": branch_to_delete_id,
            "message": f"Branch '{branch_name}' deleted successfully"
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "erase_branch",
                "description": "Deletes a branch from a repository. Cannot delete the default branch.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "Access token for authentication (will be encoded to base64 UTF-8 and compared with token_encoded) (required)"
                        },
                        "repository_id": {
                            "type": "string",
                            "description": "Repository ID to delete the branch from (required)"
                        },
                        "branch_name": {
                            "type": "string",
                            "description": "Name of the branch to delete (required)"
                        }
                    },
                    "required": ["access_token", "repository_id", "branch_name"]
                }
            }
        }import json
import base64
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class ForkRepository(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        repository_id: str,
        owner_id: str,
        owner_type: str,
        repository_name: Optional[str] = None
    ) -> str:
        def generate_id(table: Dict[str, Any]) -> str:
            if not table:
                return "1"
            return str(max(int(k) for k in table.keys()) + 1)
        
        def get_user_from_token(token: str, tokens_data: Dict[str, Any]) -> Optional[str]:
            """Encode token and find associated user_id"""
            try:
                encoded_token = base64.b64encode(token.encode('utf-8')).decode('utf-8')
                for token_info in tokens_data.values():
                    if token_info.get("token_encoded") == encoded_token:
                        return token_info.get("user_id")
                return None
            except:
                return None
        
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        repositories = data.get("repositories", {})
        users = data.get("users", {})
        organizations = data.get("organizations", {})
        access_tokens = data.get("access_tokens", {})
        branches = data.get("branches", {})
        commits = data.get("commits", {})
        directories = data.get("directories", {})
        files = data.get("files", {})
        file_contents = data.get("file_contents", {})
        
        # Validate access token
        requesting_user_id = get_user_from_token(access_token, access_tokens)
        if not requesting_user_id:
            return json.dumps({
                "success": False,
                "error": "Invalid or expired access token"
            })
        
        # Check if source repository exists
        if repository_id not in repositories:
            return json.dumps({
                "success": False,
                "error": f"Repository with ID '{repository_id}' not found"
            })
        
        source_repo = repositories[repository_id]
        
        # Validate owner exists
        if owner_type == "user":
            if owner_id not in users:
                return json.dumps({
                    "success": False,
                    "error": f"User with ID '{owner_id}' not found"
                })
        elif owner_type == "organization":
            if owner_id not in organizations:
                return json.dumps({
                    "success": False,
                    "error": f"Organization with ID '{owner_id}' not found"
                })
        else:
            return json.dumps({
                "success": False,
                "error": f"Invalid owner_type '{owner_type}'. Must be 'user' or 'organization'"
            })
        
        # Use original repository name if not provided
        fork_name = repository_name if repository_name else source_repo.get("repository_name")
        
        # Check for duplicate repository name for new owner
        for repo in repositories.values():
            if (repo.get("repository_name") == fork_name and
                repo.get("owner_id") == owner_id and
                repo.get("owner_type") == owner_type):
                return json.dumps({
                    "success": False,
                    "error": f"Repository '{fork_name}' already exists for this owner"
                })
        
        timestamp = "2026-01-01T23:59:00"
        new_repo_id = generate_id(repositories)
        
        # Create forked repository
        forked_repo = {
            "repository_id": new_repo_id,
            "repository_name": fork_name,
            "owner_type": owner_type,
            "owner_id": owner_id,
            "description": source_repo.get("description"),
            "visibility": source_repo.get("visibility"),
            "default_branch": source_repo.get("default_branch"),
            "is_fork": True,
            "parent_repository_id": repository_id,
            "is_archived": False,
            "is_template": False,
            "stars_count": 0,
            "forks_count": 0,
            "license_type": source_repo.get("license_type"),
            "created_at": timestamp,
            "updated_at": timestamp,
            "pushed_at": None
        }
        
        repositories[new_repo_id] = forked_repo
        
        # Mapping from old IDs to new IDs
        branch_id_map = {}
        commit_id_map = {}
        directory_id_map = {}
        file_id_map = {}
        
        # Collect all commits to copy (don't modify during iteration)
        commits_to_copy = []
        for commit in list(commits.values()):
            if commit.get("repository_id") == repository_id:
                commits_to_copy.append(commit)
        
        # Copy all commits from source repository
        for commit in commits_to_copy:
            old_commit_id = commit.get("commit_id")
            new_commit_id = generate_id(commits)
            commit_id_map[old_commit_id] = new_commit_id
            
            new_commit = {
                "commit_id": new_commit_id,
                "repository_id": new_repo_id,
                "commit_sha": commit.get("commit_sha"),
                "author_id": commit.get("author_id"),
                "committer_id": commit.get("committer_id"),
                "message": commit.get("message"),
                "parent_commit_id": None,
                "committed_at": commit.get("committed_at"),
                "created_at": timestamp
            }
            commits[new_commit_id] = new_commit
        
        # Update parent_commit_id references
        for commit in commits_to_copy:
            old_commit_id = commit.get("commit_id")
            new_commit_id = commit_id_map[old_commit_id]
            
            if commit.get("parent_commit_id"):
                old_parent_id = commit.get("parent_commit_id")
                if old_parent_id in commit_id_map:
                    commits[new_commit_id]["parent_commit_id"] = commit_id_map[old_parent_id]
        
        # Collect all branches to copy
        branches_to_copy = []
        for branch in list(branches.values()):
            if branch.get("repository_id") == repository_id:
                branches_to_copy.append(branch)
        
        # Copy all branches from source repository
        for branch in branches_to_copy:
            old_branch_id = branch.get("branch_id")
            new_branch_id = generate_id(branches)
            branch_id_map[old_branch_id] = new_branch_id
            
            new_branch = {
                "branch_id": new_branch_id,
                "repository_id": new_repo_id,
                "branch_name": branch.get("branch_name"),
                "commit_sha": branch.get("commit_sha"),
                "source_branch": None,
                "is_default": branch.get("is_default"),
                "created_at": timestamp,
                "updated_at": timestamp
            }
            branches[new_branch_id] = new_branch
        
        # Update source_branch references
        for branch in branches_to_copy:
            old_branch_id = branch.get("branch_id")
            new_branch_id = branch_id_map[old_branch_id]
            
            if branch.get("source_branch"):
                old_source_id = branch.get("source_branch")
                if old_source_id in branch_id_map:
                    branches[new_branch_id]["source_branch"] = branch_id_map[old_source_id]
        
        # Collect all directories to copy
        directories_to_copy = []
        for directory in list(directories.values()):
            if directory.get("repository_id") == repository_id:
                directories_to_copy.append(directory)
        
        # Copy all directories from source repository
        for directory in directories_to_copy:
            old_dir_id = directory.get("directory_id")
            new_dir_id = generate_id(directories)
            directory_id_map[old_dir_id] = new_dir_id
            
            old_branch_id = directory.get("branch_id")
            new_branch_id = branch_id_map.get(old_branch_id)
            
            new_directory = {
                "directory_id": new_dir_id,
                "repository_id": new_repo_id,
                "branch_id": new_branch_id,
                "directory_path": directory.get("directory_path"),
                "parent_directory_id": None,
                "created_at": timestamp,
                "updated_at": timestamp
            }
            directories[new_dir_id] = new_directory
        
        # Update parent_directory_id references
        for directory in directories_to_copy:
            old_dir_id = directory.get("directory_id")
            new_dir_id = directory_id_map[old_dir_id]
            
            if directory.get("parent_directory_id"):
                old_parent_id = directory.get("parent_directory_id")
                if old_parent_id in directory_id_map:
                    directories[new_dir_id]["parent_directory_id"] = directory_id_map[old_parent_id]
        
        # Collect all files to copy
        files_to_copy = []
        for file in list(files.values()):
            if file.get("repository_id") == repository_id:
                files_to_copy.append(file)
        
        # Copy all files from source repository
        for file in files_to_copy:
            old_file_id = file.get("file_id")
            new_file_id = generate_id(files)
            file_id_map[old_file_id] = new_file_id
            
            old_branch_id = file.get("branch_id")
            new_branch_id = branch_id_map.get(old_branch_id)
            
            old_dir_id = file.get("directory_id")
            new_dir_id = directory_id_map.get(old_dir_id) if old_dir_id else None
            
            old_commit_id = file.get("last_commit_id")
            new_commit_id = commit_id_map.get(old_commit_id) if old_commit_id else None
            
            new_file = {
                "file_id": new_file_id,
                "repository_id": new_repo_id,
                "branch_id": new_branch_id,
                "directory_id": new_dir_id,
                "file_path": file.get("file_path"),
                "file_name": file.get("file_name"),
                "language": file.get("language"),
                "is_binary": file.get("is_binary"),
                "last_modified_at": file.get("last_modified_at"),
                "last_commit_id": new_commit_id,
                "created_at": timestamp,
                "updated_at": timestamp
            }
            files[new_file_id] = new_file
        
        # Collect all file contents to copy
        contents_to_copy = []
        for content in list(file_contents.values()):
            old_file_id = content.get("file_id")
            if old_file_id in file_id_map:
                contents_to_copy.append(content)
        
        # Copy all file contents
        for content in contents_to_copy:
            new_content_id = generate_id(file_contents)
            old_file_id = content.get("file_id")
            new_file_id = file_id_map[old_file_id]
            
            old_commit_id = content.get("commit_id")
            new_commit_id = commit_id_map.get(old_commit_id)
            
            new_content = {
                "content_id": new_content_id,
                "file_id": new_file_id,
                "commit_id": new_commit_id,
                "content": content.get("content"),
                "encoding": content.get("encoding"),
                "created_at": timestamp
            }
            file_contents[new_content_id] = new_content
        
        # Increment forks_count on source repository
        source_repo["forks_count"] = source_repo.get("forks_count", 0) + 1
        
        return json.dumps({
            "success": True,
            "repository_id": new_repo_id,
            "parent_repository_id": repository_id,
            "repository_data": forked_repo,
            "copied_items": {
                "branches": len(branch_id_map),
                "commits": len(commit_id_map),
                "directories": len(directory_id_map),
                "files": len(file_id_map),
                "file_contents": len(contents_to_copy)
            }
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "fork_repository",
                "description": "Forks a repository to a new owner, including all branches, commits, files, and content.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "Access token for authentication (required)"
                        },
                        "repository_id": {
                            "type": "string",
                            "description": "Repository ID to fork (required)"
                        },
                        "owner_id": {
                            "type": "string",
                            "description": "ID of the new owner (user_id or organization_id) (required)"
                        },
                        "owner_type": {
                            "type": "string",
                            "description": "Type of new owner. Allowed values: 'user', 'organization' (required)",
                            "enum": ["user", "organization"]
                        },
                        "repository_name": {
                            "type": "string",
                            "description": "Name for the forked repository (optional, defaults to source repository name)"
                        }
                    },
                    "required": ["access_token", "repository_id", "owner_id", "owner_type"]
                }
            }
        }
import json
import base64
from typing import Any, Dict
from tau_bench.envs.tool import Tool


class GetRepositoryPermissions(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        repository_id: str
    ) -> str:
        valid_permissions = {'read', 'write', 'admin'}

        def get_user_from_token(token: str, tokens_data: Dict[str, Any]) -> str:
            """Encode token and find associated user_id"""
            try:
                # Encode token to base64 UTF-8
                encoded_token = base64.b64encode(token.encode('utf-8')).decode('utf-8')
                # Find token in access_tokens by comparing with token_encoded
                for token_info in tokens_data.values():
                    if token_info.get("token_encoded") == encoded_token:
                        return token_info.get("user_id")
                return None
            except:
                return None
        
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        repositories = data.get("repositories", {})
        repository_collaborators = data.get("repository_collaborators", {})
        access_tokens = data.get("access_tokens", {})
        organization_members = data.get("organization_members", {})
        
        # Validate access token and get user_id
        user_id = get_user_from_token(access_token, access_tokens)
        if not user_id:
            return json.dumps({
                "success": False,
                "error": "Invalid or expired access token"
            })
        
        # Check if repository exists
        if repository_id not in repositories:
            return json.dumps({
                "success": False,
                "error": f"Repository with ID '{repository_id}' not found"
            })
        
        repo = repositories[repository_id]
        owner_type = repo.get("owner_type")
        owner_id = repo.get("owner_id")
        
        # Check if user is the owner (Personal Account)
        if owner_type == "user" and owner_id == user_id:
            return json.dumps({
                "success": True,
                "repository_id": repository_id,
                "user_id": user_id,
                "permission_level": "admin",
                "source": "owner"
            })
        
        # Check if user is organization owner/member
        if owner_type == "organization":
            for membership in organization_members.values():
                if (membership.get("organization_id") == owner_id and 
                    membership.get("user_id") == user_id and
                    membership.get("status") == "active"):
                    
                    role = membership.get("role")
                    if role == "owner":
                        return json.dumps({
                            "success": True,
                            "repository_id": repository_id,
                            "user_id": user_id,
                            "permission_level": "admin",
                            "source": "organization_owner"
                        })
                    
                    # Organization members get read by default
                    permission = "read"
                    
                    # Check if they have explicit collaborator permissions that might upgrade them
                    for collab in repository_collaborators.values():
                        if (collab.get("repository_id") == repository_id and
                            collab.get("user_id") == user_id and
                            collab.get("status") == "active"):
                            
                            collab_perm = collab.get("permission_level")
                            if collab_perm in valid_permissions:
                                permission = collab_perm
                            break
                    
                    return json.dumps({
                        "success": True,
                        "repository_id": repository_id,
                        "user_id": user_id,
                        "permission_level": permission,
                        "source": "organization_member"
                    })
        
        # Check if user is a collaborator (for personal repos or non-org-members)
        for collab_id, collab in repository_collaborators.items():
            if (collab.get("repository_id") == repository_id and
                collab.get("user_id") == user_id and
                collab.get("status") == "active"):
                
                perm = collab.get("permission_level")
                
                # Correction: Strictly validate the permission level against allowed enum
                if perm in valid_permissions:
                    return json.dumps({
                        "success": True,
                        "repository_id": repository_id,
                        "user_id": user_id,
                        "permission_level": perm,
                        "source": "collaborator",
                        "collaborator_id": collab_id
                    })
        
        # Correction: If no valid permission is found, return False/Error 
        # instead of returning "no permission" which violates the enum schema.
        return json.dumps({
            "success": False,
            "error": "User does not have read, write, or admin access to this repository"
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "get_repository_permissions",
                "description": "Gets repository permissions for the authenticated user.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "Access token for authentication (will be encoded to base64 UTF-8 and compared with token_encoded) (required)"
                        },
                        "repository_id": {
                            "type": "string",
                            "description": "Repository ID to check permissions for (required)"
                        }
                    },
                    "required": ["access_token", "repository_id"]
                }
            }
        }import json
import base64
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class InviteOrgMember(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        organization_id: str,
        user_id: str,
        role: str
    ) -> str:
        def generate_id(table: Dict[str, Any]) -> str:
            if not table:
                return "1"
            return str(max(int(k) for k in table.keys()) + 1)
        
        def get_user_from_token(token: str, tokens_data: Dict[str, Any]) -> Optional[str]:
            """Encode token and find associated user_id"""
            try:
                encoded_token = base64.b64encode(token.encode('utf-8')).decode('utf-8')
                for token_info in tokens_data.values():
                    if token_info.get("token_encoded") == encoded_token:
                        return token_info.get("user_id")
                return None
            except:
                return None
        
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        organizations = data.get("organizations", {})
        organization_members = data.get("organization_members", {})
        users = data.get("users", {})
        access_tokens = data.get("access_tokens", {})
        
        # Validate access token
        requesting_user_id = get_user_from_token(access_token, access_tokens)
        if not requesting_user_id:
            return json.dumps({
                "success": False,
                "error": "Invalid or expired access token"
            })
        
        # Check if organization exists
        if organization_id not in organizations:
            return json.dumps({
                "success": False,
                "error": f"Organization with ID '{organization_id}' not found"
            })
        
        # Check if user exists
        if user_id not in users:
            return json.dumps({
                "success": False,
                "error": f"User with ID '{user_id}' not found"
            })
        
        # Validate role
        if role not in ["owner", "member"]:
            return json.dumps({
                "success": False,
                "error": f"Invalid role '{role}'. Must be 'owner' or 'member'"
            })
        
        # Check if requesting user is an owner of the organization
        is_owner = False
        for membership in organization_members.values():
            if (membership.get("organization_id") == organization_id and
                membership.get("user_id") == requesting_user_id and
                membership.get("role") == "owner" and
                membership.get("status") == "active"):
                is_owner = True
                break
        
        if not is_owner:
            return json.dumps({
                "success": False,
                "error": "Insufficient permissions. Only organization owners can invite members"
            })
        
        # Check if user is already a member
        for membership in organization_members.values():
            if (membership.get("organization_id") == organization_id and
                membership.get("user_id") == user_id):
                return json.dumps({
                    "success": False,
                    "error": f"User is already a member of this organization"
                })
        
        timestamp = "2026-01-01T23:59:00"
        new_membership_id = generate_id(organization_members)
        
        new_membership = {
            "membership_id": new_membership_id,
            "organization_id": organization_id,
            "user_id": user_id,
            "role": role,
            "status": "active",
            "joined_at": timestamp
        }
        
        organization_members[new_membership_id] = new_membership
        
        return json.dumps({
            "success": True,
            "membership_id": new_membership_id,
            "membership_data": new_membership
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "invite_org_member",
                "description": "Invites a user to join an organization.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "Access token for authentication (required)"
                        },
                        "organization_id": {
                            "type": "string",
                            "description": "Organization ID to invite the user to (required)"
                        },
                        "user_id": {
                            "type": "string",
                            "description": "User ID to invite (required)"
                        },
                        "role": {
                            "type": "string",
                            "description": "Role to assign. Allowed values: 'owner', 'member' (required)",
                            "enum": ["owner", "member"]
                        }
                    },
                    "required": ["access_token", "organization_id", "user_id", "role"]
                }
            }
        }

import json
import base64
from typing import Any, Dict
from tau_bench.envs.tool import Tool


class ListAccessTokens(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        user_id: str
    ) -> str:
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format for access tokens"
            })
        
        access_tokens = data.get("access_tokens", {})
        results = []
        
        for token_id, token_data in access_tokens.items():
            if user_id and token_data.get("user_id") != user_id:
                continue

            # Decode first
            token_decoded = None
            try:
                token_encoded = token_data.get("token_encoded", "")
                token_decoded = base64.b64decode(token_encoded).decode("utf-8")
            except Exception:
                token_decoded = None

            # Copy token_data so original is untouched
            safe_token_data = token_data.copy()
            safe_token_data.pop("token_encoded", None)

            result_entry = {
                **safe_token_data,
                "token_id": token_id,
                "token": token_decoded
            }
            results.append(result_entry)

        
        return json.dumps({
            "success": True,
            "count": len(results),
            "results": results
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "list_access_tokens",
                "description": "Lists access tokens for a user.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "user_id": {
                            "type": "string",
                            "description": "Filter by user_id (exact match)"
                        }
                    },
                    "required": ["user_id"]
                }
            }
        }import json
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class ListBranches(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        repository_id: Optional[str] = None,
        branch_name: Optional[str] = None,
        is_default: Optional[bool] = None,
        branch_id: Optional[str] = None
    ) -> str:
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format for branches"
            })
        
        # Validate is_default if provided (must be boolean)
        if is_default is not None and not isinstance(is_default, bool):
            return json.dumps({
                "success": False,
                "error": f"Invalid is_default value. Must be True or False"
            })
        
        branches = data.get("branches", {})
        results = []
        
        for b_id, branch_data in branches.items():
            # Apply filters
            if repository_id and branch_data.get("repository_id") != repository_id:
                continue
            if branch_name and branch_data.get("branch_name") != branch_name:
                continue
            if is_default is not None and branch_data.get("is_default") != is_default:
                continue
            if branch_id and b_id != branch_id:
                continue
            
            results.append({**branch_data, "branch_id": b_id})
        
        return json.dumps({
            "success": True,
            "count": len(results),
            "results": results
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "list_branches",
                "description": "Lists branches from repositories.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "repository_id": {
                            "type": "string",
                            "description": "Filter by repository_id (exact match) (optional)"
                        },
                        "branch_name": {
                            "type": "string",
                            "description": "Filter by branch name (exact match) (optional)"
                        },
                        "is_default": {
                            "type": "boolean",
                            "description": "Filter by default branch status. Allowed values: True, False (optional)"
                        },
                        "branch_id": {
                            "type": "string",
                            "description": "Filter by branch_id (exact match) (optional)"
                        }
                    },
                    "required": []
                }
            }
        }

import json
from typing import Any, Dict
from tau_bench.envs.tool import Tool

class ListComments(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        commentable_type: str,
        commentable_id: str,
        author_id: str
    ) -> str:
        comments = data.get("comments", {})
        results = []

        valid_types = ['issue', 'pull_request']
        if commentable_type not in valid_types:
            return json.dumps({"error": f"Invalid commentable_type. Must be one of: {', '.join(valid_types)}"})

        for comment in comments.values():
            if (comment.get("commentable_type") == commentable_type and
                comment.get("commentable_id") == commentable_id and
                comment.get("author_id") == author_id):
                results.append(comment)

        return json.dumps(results)

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "list_comments",
                "description": "Lists comments for a specific entity type and ID, authored by a specific user.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "commentable_type": {
                            "type": "string",
                            "description": "The type of entity the comment belongs to. Allowed values: 'issue', 'pull_request'.",
                            "enum": ["issue", "pull_request"]
                        },
                        "commentable_id": {
                            "type": "string",
                            "description": "The ID of the entity (issue ID or PR ID)."
                        },
                        "author_id": {
                            "type": "string",
                            "description": "The ID of the author."
                        }
                    },
                    "required": ["commentable_type", "commentable_id", "author_id"]
                }
            }
        }
import json
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool

class ListFilesDirectories(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        search_type: str,
        repository_id: Optional[str] = None,
        branch_id: Optional[str] = None,
        parent_directory_id: Optional[str] = None,
        directory_path: Optional[str] = None,
        file_name: Optional[str] = None,
        language: Optional[str] = None,
        file_id: Optional[str] = None,
        directory_id: Optional[str] = None
    ) -> str:
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        # Validate search_type
        if search_type not in ["file", "directory"]:
            return json.dumps({
                "success": False,
                "error": f"Invalid search_type '{search_type}'. Must be 'file' or 'directory'"
            })
        
        # Validate language if provided 
        valid_languages = [
            'C', 'C++', 'C#', 'Go', 'Rust', 'Java', 'Kotlin', 'Scala', 'Python', 'Ruby', 'PHP',
            'JavaScript', 'TypeScript', 'Shell', 'PowerShell', 'Swift', 'Objective-C', 'Dart',
            'R', 'MATLAB', 'Groovy', 'Perl', 'Lua', 'Haskell', 'Elixir', 'Erlang', 'Julia',
            'Assembly', 'Fortran', 'COBOL', 'HTML', 'CSS', 'SCSS', 'Less', 'Markdown', 'AsciiDoc',
            'JSON', 'YAML', 'XML', 'TOML', 'INI', 'CSV', 'Dockerfile', 'Makefile', 'Bash',
            'Terraform', 'Ansible', 'SQL', 'PLpgSQL', 'Text', 'Binary', 'Unknown'
        ]
        
        if language and language not in valid_languages:
            return json.dumps({
                "success": False,
                "error": f"Invalid language '{language}'. Must be one of the supported languages"
            })

        def get_results_for_branch(target_branch_id: Optional[str]):
            results = []
            if search_type == "file":
                files = data.get("files", {})
                for f_id, file_data in files.items():
                    if repository_id and file_data.get("repository_id") != repository_id: continue
                    if target_branch_id and file_data.get("branch_id") != target_branch_id: continue
                    if parent_directory_id and file_data.get("directory_id") != parent_directory_id: continue
                    if file_name and file_data.get("file_name") != file_name: continue
                    if language and file_data.get("language") != language: continue
                    if file_id and f_id != file_id: continue
                    results.append({**file_data, "file_id": f_id, "item_type": "file"})
            
            elif search_type == "directory":
                directories = data.get("directories", {})
                for d_id, dir_data in directories.items():
                    if repository_id and dir_data.get("repository_id") != repository_id: continue
                    if target_branch_id and dir_data.get("branch_id") != target_branch_id: continue
                    if parent_directory_id and dir_data.get("parent_directory_id") != parent_directory_id: continue
                    if directory_path and dir_data.get("directory_path") != directory_path: continue
                    if directory_id and d_id != directory_id: continue
                    results.append({**dir_data, "directory_id": d_id, "item_type": "directory"})
            return results

        
        current_branch_search = branch_id
        final_results = []
        
        max_depth = 10 
        attempts = 0

        while attempts < max_depth:
            final_results = get_results_for_branch(current_branch_search)            
            if final_results or not current_branch_search:
                break
            
            branches = data.get("branches", {})
            branch_obj = None
            
            if current_branch_search in branches:
                branch_obj = branches[current_branch_search]
            else:
                for b in branches.values():
                    if b.get("branch_id") == current_branch_search:
                        branch_obj = b
                        break
            
            if branch_obj and branch_obj.get("source_branch"):
                current_branch_search = branch_obj.get("source_branch")
                attempts += 1
            else:
                break

        return json.dumps({
            "success": True,
            "count": len(final_results),
            "search_type": search_type,
            "results": final_results,
            "resolved_branch_id": current_branch_search 
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "list_files_directories",
                "description": "Lists either files or directories from repositories based on the search_type.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "search_type": {
                            "type": "string",
                            "description": "Type of items to search for. Allowed values: 'file', 'directory' (required)",
                            "enum": ["file", "directory"]
                        },
                        "repository_id": {
                            "type": "string",
                            "description": "Filter by repository_id (exact match) (optional)"
                        },
                        "branch_id": {
                            "type": "string",
                            "description": "Filter by branch_id (exact match) (optional)"
                        },
                        "parent_directory_id": {
                            "type": "string",
                            "description": "Filter by parent directory ID (exact match) - for files, this filters by directory_id; for directories, this filters by parent_directory_id (optional)"
                        },
                        "directory_path": {
                            "type": "string",
                            "description": "Filter by directory path (exact match) - only applies when search_type='directory' (optional)"
                        },
                        "file_name": {
                            "type": "string",
                            "description": "Filter by file name (exact match) - only applies when search_type='file' (optional)"
                        },
                        "language": {
                            "type": "string",
                            "description": "Filter by programming language (exact match) - only applies when search_type='file'. Allowed values: 'C', 'C++', 'C#', 'Go', 'Rust', 'Java', 'Kotlin', 'Scala', 'Python', 'Ruby', 'PHP', 'JavaScript', 'TypeScript', 'Shell', 'PowerShell', 'Swift', 'Objective-C', 'Dart', 'R', 'MATLAB', 'Groovy', 'Perl', 'Lua', 'Haskell', 'Elixir', 'Erlang', 'Julia', 'Assembly', 'Fortran', 'COBOL', 'HTML', 'CSS', 'SCSS', 'Less', 'Markdown', 'AsciiDoc', 'JSON', 'YAML', 'XML', 'TOML', 'INI', 'CSV', 'Dockerfile', 'Makefile', 'Bash', 'Terraform', 'Ansible', 'SQL', 'PLpgSQL', 'Text', 'Binary', 'Unknown' (optional)",
                            "enum": [
                                'C', 'C++', 'C#', 'Go', 'Rust', 'Java', 'Kotlin', 'Scala', 'Python', 'Ruby', 'PHP',
                                'JavaScript', 'TypeScript', 'Shell', 'PowerShell', 'Swift', 'Objective-C', 'Dart',
                                'R', 'MATLAB', 'Groovy', 'Perl', 'Lua', 'Haskell', 'Elixir', 'Erlang', 'Julia',
                                'Assembly', 'Fortran', 'COBOL', 'HTML', 'CSS',  'SCSS', 'Less', 'Markdown', 'AsciiDoc',
                                'JSON', 'YAML', 'XML', 'TOML', 'INI', 'CSV', 'Dockerfile', 'Makefile', 'Bash',
                                'Terraform', 'Ansible', 'SQL', 'PLpgSQL', 'Text', 'Binary', 'Unknown'
                            ]
                        },
                        "file_id": {
                            "type": "string",
                            "description": "Filter by file_id (exact match) - only applies when search_type='file' (optional)"
                        },
                        "directory_id": {
                            "type": "string",
                            "description": "Filter by directory_id (exact match) - only applies when search_type='directory' (optional)"
                        }
                    },
                    "required": ["search_type"]
                }
            }
        }import json
import base64
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class ListLabels(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        repository_id: str,
        issue_id: Optional[str] = None,
        pull_request_id: Optional[str] = None
    ) -> str:
        def get_user_from_token(token: str, tokens_data: Dict[str, Any]) -> Optional[str]:
            """Encode token and find associated user_id"""
            try:
                encoded_token = base64.b64encode(token.encode('utf-8')).decode('utf-8')
                for token_info in tokens_data.values():
                    if token_info.get("token_encoded") == encoded_token:
                        return token_info.get("user_id")
                return None
            except:
                return None

        if not isinstance(data, dict):
            return json.dumps({"success": False, "error": "Invalid data format"})

        repositories = data.get("repositories", {})
        labels = data.get("labels", {})
        access_tokens = data.get("access_tokens", {})
        repository_collaborators = data.get("repository_collaborators", {})
        organization_members = data.get("organization_members", {})
        issues = data.get("issues", {})
        pull_requests = data.get("pull_requests", {})

        # Validate access token
        requesting_user_id = get_user_from_token(access_token, access_tokens)
        if not requesting_user_id:
            return json.dumps({"success": False, "error": "Invalid or expired access token"})

        # Check if repository exists
        if repository_id not in repositories:
            return json.dumps({"success": False, "error": f"Repository with ID '{repository_id}' not found"})

        repository = repositories[repository_id]

        # permission check
        has_access = False
        if repository.get("visibility") == "public":
            has_access = True

        if not has_access and repository.get("owner_type") == "user" and repository.get("owner_id") == requesting_user_id:
            has_access = True

        if not has_access:
            for collab in repository_collaborators.values():
                if (collab.get("repository_id") == repository_id and
                    collab.get("user_id") == requesting_user_id and
                    collab.get("status") == "active"):
                    has_access = True
                    break

        if not has_access and repository.get("owner_type") == "organization":
            for membership in organization_members.values():
                if (membership.get("organization_id") == repository.get("owner_id") and
                    membership.get("user_id") == requesting_user_id and
                    membership.get("status") == "active"):
                    has_access = True
                    break

        if not has_access:
            return json.dumps({"success": False, "error": "Insufficient permissions. You do not have access to this repository."})

        # Filter by Repository
        repo_labels = [l for l in labels.values() if l.get("repository_id") == repository_id]

        # Filter by Issue if provided
        if issue_id:
            if issue_id not in issues:
                 return json.dumps({"success": False, "error": f"Issue '{issue_id}' not found"})

            # Convert target number to string for safe comparison
            target_issue_num = str(issues[issue_id].get("issue_number"))

            filtered_labels = []
            for label in repo_labels:
                issue_ids_str = label.get("issue_ids")
                if issue_ids_str:
                    try:
                        # Parse the JSON string
                        attached_issues = json.loads(issue_ids_str)
                        if isinstance(attached_issues, list):
                            # Convert all elements in the list to strings to handle mixed types (int vs string)
                            attached_issues_str = [str(x) for x in attached_issues]
                            if target_issue_num in attached_issues_str:
                                filtered_labels.append(label)
                    except:
                        pass 
            repo_labels = filtered_labels

        # Filter by Pull Request if provided
        elif pull_request_id:
            if pull_request_id not in pull_requests:
                 return json.dumps({"success": False, "error": f"Pull Request '{pull_request_id}' not found"})

            # Convert target number to string for safe comparison
            target_pr_num = str(pull_requests[pull_request_id].get("pull_request_number"))

            filtered_labels = []
            for label in repo_labels:
                pr_ids_str = label.get("pr_ids")
                if pr_ids_str:
                    try:
                        attached_prs = json.loads(pr_ids_str)
                        if isinstance(attached_prs, list):
                            # Convert all elements in the list to strings
                            attached_prs_str = [str(x) for x in attached_prs]
                            if target_pr_num in attached_prs_str:
                                filtered_labels.append(label)
                    except:
                        pass
            repo_labels = filtered_labels

        # Sort by creation date
        repo_labels.sort(key=lambda x: x.get("created_at", ""), reverse=True)

        return json.dumps({
            "success": True,
            "repository_id": repository_id,
            "issue_id": issue_id,
            "pull_request_id": pull_request_id,
            "total_count": len(repo_labels),
            "labels": repo_labels
        })

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "list_labels",
                "description": "Lists labels defined in a repository.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "Access token for authentication (required)"
                        },
                        "repository_id": {
                            "type": "string",
                            "description": "Repository ID to list labels for (required)"
                        },
                        "issue_id": {
                            "type": "string",
                            "description": "Filter labels attached to this Issue ID (optional)"
                        },
                        "pull_request_id": {
                            "type": "string",
                            "description": "Filter labels attached to this Pull Request ID (optional)"
                        }
                    },
                    "required": ["access_token", "repository_id"]
                }
            }
        }
import json
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class ListOrgMembers(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        organization_id: Optional[str] = None,
        role: Optional[str] = None,
        status: Optional[str] = None
    ) -> str:
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format for organization members"
            })
        
        # Validate role if provided
        if role and role not in ["owner", "member"]:
            return json.dumps({
                "success": False,
                "error": f"Invalid role '{role}'. Must be 'owner' or 'member'"
            })
        
        # Validate status if provided
        if status and status not in ["active", "pending", "inactive"]:
            return json.dumps({
                "success": False,
                "error": f"Invalid status '{status}'. Must be 'active', 'pending', or 'inactive'"
            })
        
        organization_members = data.get("organization_members", {})
        results = []
        
        for member_id, member_data in organization_members.items():
            # Apply filters
            if organization_id and member_data.get("organization_id") != organization_id:
                continue
            if role and member_data.get("role") != role:
                continue
            if status and member_data.get("status") != status:
                continue
            
            results.append({**member_data, "membership_id": member_id})
        
        return json.dumps({
            "success": True,
            "count": len(results),
            "results": results
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "list_org_members",
                "description": "Lists organization members with optional filters.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "organization_id": {
                            "type": "string",
                            "description": "Filter by organization_id (exact match) (optional)"
                        },
                        "role": {
                            "type": "string",
                            "description": "Filter by role. Allowed values: 'owner', 'member' (optional)",
                            "enum": ["owner", "member"]
                        },
                        "status": {
                            "type": "string",
                            "description": "Filter by status. Allowed values: 'active', 'pending', 'inactive' (optional)",
                            "enum": ["active", "pending", "inactive"]
                        }
                    },
                    "required": []
                }
            }
        }

import json
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class ListOrganizations(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        organization_name: Optional[str] = None,
        visibility: Optional[str] = None,
        plan_type: Optional[str] = None,
        organization_id: Optional[str] = None
    ) -> str:
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format for organizations"
            })
        
        # Validate visibility if provided
        if visibility and visibility not in ["public", "limited", "private"]:
            return json.dumps({
                "success": False,
                "error": f"Invalid visibility '{visibility}'. Must be 'public', 'limited', or 'private'"
            })
        
        # Validate plan_type if provided
        if plan_type and plan_type not in ["free", "team", "enterprise"]:
            return json.dumps({
                "success": False,
                "error": f"Invalid plan_type '{plan_type}'. Must be 'free', 'team', or 'enterprise'"
            })
        
        organizations = data.get("organizations", {})
        results = []
        
        for org_id, org_data in organizations.items():
            # Apply filters
            if organization_name and org_data.get("organization_name") != organization_name:
                continue
            if visibility and org_data.get("visibility") != visibility:
                continue
            if plan_type and org_data.get("plan_type") != plan_type:
                continue
            if organization_id and org_id != organization_id:
                continue
            
            results.append({**org_data, "organization_id": org_id})
        
        return json.dumps({
            "success": True,
            "count": len(results),
            "results": results
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "list_organizations",
                "description": "Lists organizations with optional filters.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "organization_name": {
                            "type": "string",
                            "description": "Filter by organization name (exact match) (optional)"
                        },
                        "visibility": {
                            "type": "string",
                            "description": "Filter by visibility. Allowed values: 'public', 'limited', 'private' (optional)",
                            "enum" : ["public", "limited", "private"]
                        },
                        "plan_type": {
                            "type": "string",
                            "description": "Filter by plan type. Allowed values: 'free', 'team', 'enterprise' (optional)",
                            "enum" : ["free", "team", "enterprise"]
                        },
                        "organization_id": {
                            "type": "string",
                            "description": "Filter by organization_id (exact match) (optional)"
                        }
                    },
                    "required": []
                }
            }
        }

import json
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class ListPullRequests(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        repository_id: Optional[str] = None,
        status: Optional[str] = None,
        author_id: Optional[str] = None,
        source_branch: Optional[str] = None,
        target_branch: Optional[str] = None,
        pull_request_id: Optional[str] = None
    ) -> str:
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        # Validate status if provided
        if status and status not in ["open", "closed", "merged", "draft"]:
            return json.dumps({
                "success": False,
                "error": f"Invalid status '{status}'. Must be 'open', 'closed', 'merged', or 'draft'"
            })
        
        pull_requests = data.get("pull_requests", {})
        results = []
        
        for pr_id, pr_data in pull_requests.items():
            # Apply filters
            if repository_id and pr_data.get("repository_id") != repository_id:
                continue
            if status and pr_data.get("status") != status:
                continue
            if author_id and pr_data.get("author_id") != author_id:
                continue
            if source_branch and pr_data.get("source_branch") != source_branch:
                continue
            if target_branch and pr_data.get("target_branch") != target_branch:
                continue
            if pull_request_id and pr_id != pull_request_id:
                continue
            
            results.append({**pr_data, "pull_request_id": pr_id})
        
        return json.dumps({
            "success": True,
            "count": len(results),
            "results": results
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "list_pull_requests",
                "description": "Lists pull requests with optional filters.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "repository_id": {
                            "type": "string",
                            "description": "Filter by repository_id (exact match) (optional)"
                        },
                        "status": {
                            "type": "string",
                            "description": "Filter by status. Allowed values: 'open', 'closed', 'merged', 'draft' (exact match) (optional)",
                            "enum" : ["open", "closed", "merged", "draft"]
                        },
                        "author_id": {
                            "type": "string",
                            "description": "Filter by author_id (exact match) (optional)"
                        },
                        "source_branch": {
                            "type": "string",
                            "description": "Filter by source branch name (exact match) (optional)"
                        },
                        "target_branch": {
                            "type": "string",
                            "description": "Filter by target branch name (exact match) (optional)"
                        },
                        "pull_request_id": {
                            "type": "string",
                            "description": "Filter by pull_request_id (exact match) (optional)"
                        }
                    },
                    "required": []
                }
            }
        }


import json
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool

class ListReleases(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        repository_id: str,
        is_draft: Optional[bool] = None,
        is_prerelease: Optional[bool] = None,
        author_id: Optional[str] = None
    ) -> str:
        releases = data.get("releases", {})
        repositories = data.get("repositories", {})

        if repository_id not in repositories:
            return json.dumps({"error": f"Repository {repository_id} not found"})

        results = []
        for release in releases.values():
            if release.get("repository_id") != repository_id:
                continue
            
            match = True
            if is_draft is not None and release.get("is_draft") != is_draft:
                match = False
            if is_prerelease is not None and release.get("is_prerelease") != is_prerelease:
                match = False
            if author_id is not None and release.get("author_id") != author_id:
                match = False
            
            if match:
                results.append(release)

        return json.dumps(results)

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "list_releases",
                "description": "Lists releases for a repository with optional filters.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "repository_id": {
                            "type": "string",
                            "description": "The ID of the repository."
                        },
                        "is_draft": {
                            "type": "boolean",
                            "description": "Filter by draft status (True/False) (optional)"
                        },
                        "is_prerelease": {
                            "type": "boolean",
                            "description": "Filter by prerelease status (True/False) (optional)"
                        },
                        "author_id": {
                            "type": "string",
                            "description": "Filter by author ID (optional)"
                        }
                    },
                    "required": ["repository_id"]
                }
            }
        }import json
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class ListRepositories(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        owner_id: Optional[str] = None,
        owner_type: Optional[str] = None,
        visibility: Optional[str] = None,
        is_archived: Optional[bool] = None,
        repository_name: Optional[str] = None,
        repository_id: Optional[str] = None
    ) -> str:
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format for repositories"
            })
        
        # Validate owner_type if provided
        if owner_type and owner_type not in ["user", "organization"]:
            return json.dumps({
                "success": False,
                "error": f"Invalid owner_type '{owner_type}'. Must be 'user' or 'organization'"
            })
        
        # Validate visibility if provided
        if visibility and visibility not in ["public", "private", "internal"]:
            return json.dumps({
                "success": False,
                "error": f"Invalid visibility '{visibility}'. Must be 'public', 'private', or 'internal'"
            })
        
        # Validate is_archived if provided (must be boolean)
        if is_archived is not None and not isinstance(is_archived, bool):
            return json.dumps({
                "success": False,
                "error": f"Invalid is_archived value. Must be True or False"
            })
        
        repositories = data.get("repositories", {})
        results = []
        
        for repo_id, repo_data in repositories.items():
            # Apply filters
            if owner_id and repo_data.get("owner_id") != owner_id:
                continue
            if owner_type and repo_data.get("owner_type") != owner_type:
                continue
            if visibility and repo_data.get("visibility") != visibility:
                continue
            if is_archived is not None and repo_data.get("is_archived") != is_archived:
                continue
            if repository_name and repo_data.get("repository_name") != repository_name:
                continue
            if repository_id and repo_id != repository_id:
                continue
            
            # Create a filtered copy excluding 'project_id'
            filtered_data = {k: v for k, v in repo_data.items() if k != "project_id"}
            
            # Append the filtered data combined with the repository_id
            results.append({**filtered_data, "repository_id": repo_id})
        
        return json.dumps({
            "success": True,
            "count": len(results),
            "results": results
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "list_repositories",
                "description": "Lists repositories with optional filters.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "owner_id": {
                            "type": "string",
                            "description": "Filter by owner_id (exact match) (optional)"
                        },
                        "owner_type": {
                            "type": "string",
                            "description": "Filter by owner type. Allowed values: 'user', 'organization' (optional)",
                            "enum" : ["user", "organization"]
                        },
                        "visibility": {
                            "type": "string",
                            "description": "Filter by visibility. Allowed values: 'public', 'private', 'internal' (optional)",
                            "enum" : ["public", "private", "internal"]
                        },
                        "is_archived": {
                            "type": "boolean",
                            "description": "Filter by archived status. Allowed values: True, False (optional)"
                        },
                        "repository_name": {
                            "type": "string",
                            "description": "Filter by repository name (exact match) (optional)"
                        },
                        "repository_id": {
                            "type": "string",
                            "description": "Filter by repository_id (exact match) (optional)"
                        }
                    },
                    "required": []
                }
            }
        }import json
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool

class ListStars(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        user_id: Optional[str] = None,
        repository_id: Optional[str] = None
    ) -> str:
        stars = data.get("stars", {})
        users = data.get("users", {})
        repositories = data.get("repositories", {})

        # Validate existence of provided IDs
        if user_id and user_id not in users:
            return json.dumps({"error": f"User {user_id} not found"})
        
        if repository_id and repository_id not in repositories:
            return json.dumps({"error": f"Repository {repository_id} not found"})

        results = []
        for star in stars.values():
            match = True
            if user_id and star.get("user_id") != user_id:
                match = False
            if repository_id and star.get("repository_id") != repository_id:
                match = False

            if match:
                results.append(star)

        return json.dumps(results)

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "list_stars",
                "description": "Lists repository stars filtered by user or repository.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "user_id": {
                            "type": "string",
                            "description": "Filter stars by user ID (optional)"
                        },
                        "repository_id": {
                            "type": "string",
                            "description": "Filter stars by repository ID (optional)"
                        }
                    },
                    "required": []
                }
            }
        }import json
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class ListUsers(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        username: Optional[str] = None,
        user_id: Optional[str] = None,
        account_type: Optional[str] = None
    ) -> str:
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format for users"
            })
        
        users = data.get("users", {})
        results = []
        
        for uid, user_data in users.items():
            # Apply filters
            if username and user_data.get("username") != username:
                continue
            if user_id and uid != user_id:
                continue
            if account_type and user_data.get("account_type") != account_type:
                continue
            
            # Remove plan_type from output if it exists
            filtered_data = {k: v for k, v in user_data.items() if k != "plan_type"}
            
            results.append({**filtered_data, "user_id": uid})
        
        return json.dumps({
            "success": True,
            "count": len(results),
            "results": results
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "list_users",
                "description": "Lists users with optional filters.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "username": {
                            "type": "string",
                            "description": "Filter by username (exact match) (optional)"
                        },
                        "user_id": {
                            "type": "string",
                            "description": "Filter by user_id (exact match) (optional)"
                        },
                        "account_type": {
                            "type": "string",
                            "description": "Filter by account type. Allowed values: 'personal', 'organization' (optional)",
                            "enum" : ["personal", "organization"]
                        }
                    },
                    "required": []
                }
            }
        }import json
from typing import Any, Dict
from tau_bench.envs.tool import Tool

class ListWorkflows(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        repository_id: str
    ) -> str:
        workflows = data.get("workflows", {})
        repositories = data.get("repositories", {})

        if repository_id not in repositories:
            return json.dumps({"error": f"Repository {repository_id} not found"})

        results = []
        for workflow in workflows.values():
            if workflow.get("repository_id") == repository_id:
                results.append(workflow)

        return json.dumps(results)

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "list_workflows",
                "description": "Lists all CI/CD workflows for a given repository.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "repository_id": {
                            "type": "string",
                            "description": "The ID of the repository to list workflows for."
                        }
                    },
                    "required": ["repository_id"]
                }
            }
        }import json
import base64
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class RemoveOrgMember(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        organization_id: str,
        user_id: str
    ) -> str:
        def get_user_from_token(token: str, tokens_data: Dict[str, Any]) -> Optional[str]:
            """Encode token and find associated user_id"""
            try:
                encoded_token = base64.b64encode(token.encode('utf-8')).decode('utf-8')
                for token_info in tokens_data.values():
                    if token_info.get("token_encoded") == encoded_token:
                        return token_info.get("user_id")
                return None
            except:
                return None
        
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        organizations = data.get("organizations", {})
        organization_members = data.get("organization_members", {})
        access_tokens = data.get("access_tokens", {})
        
        # Validate access token
        requesting_user_id = get_user_from_token(access_token, access_tokens)
        if not requesting_user_id:
            return json.dumps({
                "success": False,
                "error": "Invalid or expired access token"
            })
        
        # Check if organization exists
        if organization_id not in organizations:
            return json.dumps({
                "success": False,
                "error": f"Organization with ID '{organization_id}' not found"
            })
        
        # Check if requesting user is an owner of the organization
        is_owner = False
        for membership in organization_members.values():
            if (membership.get("organization_id") == organization_id and
                membership.get("user_id") == requesting_user_id and
                membership.get("role") == "owner" and
                membership.get("status") == "active"):
                is_owner = True
                break
        
        if not is_owner:
            return json.dumps({
                "success": False,
                "error": "Insufficient permissions. Only organization owners can remove members"
            })
        
        # Find the membership to be removed and check if user is an owner
        membership_found = False
        removed_membership_id = None
        user_is_owner = False
        
        for membership_id, membership in organization_members.items():
            if (membership.get("organization_id") == organization_id and
                membership.get("user_id") == user_id and
                membership.get("status") == "active"):
                membership_found = True
                removed_membership_id = membership_id
                user_is_owner = membership.get("role") == "owner"
                break
        
        if not membership_found:
            return json.dumps({
                "success": False,
                "error": f"User is not an active member of this organization"
            })
        
        # If removing an owner, check if there will be at least one owner remaining
        if user_is_owner:
            active_owner_count = 0
            for membership in organization_members.values():
                if (membership.get("organization_id") == organization_id and
                    membership.get("role") == "owner" and
                    membership.get("status") == "active"):
                    active_owner_count += 1
            
            if active_owner_count <= 1:
                return json.dumps({
                    "success": False,
                    "error": "Cannot remove the last owner from the organization. Transfer ownership to another member first"
                })
        
        # Remove the member by setting status to inactive
        organization_members[removed_membership_id]["status"] = "inactive"
        
        return json.dumps({
            "success": True,
            "membership_id": removed_membership_id,
            "message": f"User {user_id} removed from organization {organization_id}"
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "remove_org_member",
                "description": "Removes a user from an organization by setting their membership status to inactive.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "Access token for authentication (required)"
                        },
                        "organization_id": {
                            "type": "string",
                            "description": "Organization ID to remove the user from (required)"
                        },
                        "user_id": {
                            "type": "string",
                            "description": "User ID to remove (required)"
                        }
                    },
                    "required": ["access_token", "organization_id", "user_id"]
                }
            }
        }import json
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool

class SearchIssues(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        repository_id: Optional[str] = None,
        issue_number: Optional[int] = None,
        status: Optional[str] = None,
        author_id: Optional[str] = None,
        assignee_id: Optional[str] = None,
        priority: Optional[str] = None,
        issue_type: Optional[str] = None
    ) -> str:
        issues = data.get("issues", {})
        results = []

        for issue in issues.values():
            match = True
            if repository_id and issue.get("repository_id") != repository_id:
                match = False
            if issue_number is not None and issue.get("issue_number") != issue_number:
                match = False
            if status and issue.get("status") != status:
                match = False
            if author_id and issue.get("author_id") != author_id:
                match = False
            if assignee_id and issue.get("assignee_id") != assignee_id:
                match = False
            if priority and issue.get("priority") != priority:
                match = False
            if issue_type and issue.get("issue_type") != issue_type:
                match = False
            
            if match:
                results.append(issue)

        return json.dumps(results)

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "search_issues",
                "description": "Searches for issues matching the provided criteria.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "repository_id": {
                            "type": "string",
                            "description": "Filter by repository ID (optional)"
                        },
                        "issue_number": {
                            "type": "integer",
                            "description": "Filter by issue number (optional)"
                        },
                        "status": {
                            "type": "string",
                            "description": "Filter by issue status. Allowed values: 'open', 'closed', 'in_progress' (optional)",
                            "enum": ["open", "closed", "in_progress"]
                        },
                        "author_id": {
                            "type": "string",
                            "description": "Filter by author ID (optional)"
                        },
                        "assignee_id": {
                            "type": "string",
                            "description": "Filter by assignee ID (optional)"
                        },
                        "priority": {
                            "type": "string",
                            "description": "Filter by priority. Allowed values: 'low', 'medium', 'high', 'critical' (optional)",
                            "enum": ["low", "medium", "high", "critical"]
                        },
                        "issue_type": {
                            "type": "string",
                            "description": "Filter by issue type. Allowed values: 'bug', 'feature', 'documentation', 'question', 'enhancement' (optional)",
                            "enum": ["bug", "feature", "documentation", "question", "enhancement"]
                        }
                    },
                    "required": []
                }
            }
        }import json
import base64
from typing import Any, Dict
from tau_bench.envs.tool import Tool

class StarUnstarRepo(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        user_id: str,
        repository_id: str,
        action: str
    ) -> str:
        def generate_id(table: Dict[str, Any]) -> str:
            if not table:
                return "1"
            return str(max(int(k) for k in table.keys()) + 1)

        timestamp = "2026-01-01T23:59:00"

        try:
            encoded_input_token = base64.b64encode(access_token.encode('utf-8')).decode('utf-8')
        except Exception:
            return json.dumps({"error": "Failed to process access token"})

        tokens = data.get("access_tokens", {})
        valid_token = False
        
        for token in tokens.values():
            if token.get("token_encoded") == encoded_input_token and token.get("status") == "active":
                if token.get("expires_at") > timestamp:
                    valid_token = True
                    break
        
        if not valid_token:
            return json.dumps({"error": "Invalid or expired access token"})

        users = data.get("users", {})
        repositories = data.get("repositories", {})
        stars = data.get("stars", {})

        if user_id not in users:
            return json.dumps({"error": f"User {user_id} not found"})
        if repository_id not in repositories:
            return json.dumps({"error": f"Repository {repository_id} not found"})

        if action not in ['star', 'unstar']:
            return json.dumps({"error": "Invalid action. Must be 'star' or 'unstar'"})

        # Check if already starred
        existing_star_id = None
        for star_id, star in stars.items():
            if star.get("user_id") == user_id and star.get("repository_id") == repository_id:
                existing_star_id = star_id
                break

        if action == 'star':
            if existing_star_id:
                # Idempotent: return existing record
                return json.dumps(stars[existing_star_id])
            else:
                new_id = generate_id(stars)
                new_star = {
                    "star_id": new_id,
                    "user_id": user_id,
                    "repository_id": repository_id,
                    "starred_at": timestamp
                }
                stars[new_id] = new_star
                return json.dumps(new_star)
        
        elif action == 'unstar':
            if existing_star_id:
                record = stars.pop(existing_star_id)
                return json.dumps(record)
            else:
                return json.dumps({"error": "Repository is not starred by this user"})

        return json.dumps({"error": "Unexpected error"})

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "star_unstar_repo",
                "description": "Stars or unstars a repository for a user.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "The access token for authentication."
                        },
                        "user_id": {
                            "type": "string",
                            "description": "The ID of the user performing the action."
                        },
                        "repository_id": {
                            "type": "string",
                            "description": "The ID of the repository to star/unstar."
                        },
                        "action": {
                            "type": "string",
                            "description": "The action to perform. Allowed values: 'star', 'unstar'.",
                            "enum": ["star", "unstar"]
                        }
                    },
                    "required": ["access_token", "user_id", "repository_id", "action"]
                }
            }
        }import json
import base64
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class SubmitPrReview(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        pull_request_id: str,
        review_state: str,
        review_body: Optional[str] = None
    ) -> str:
        def generate_id(table: Dict[str, Any]) -> str:
            if not table:
                return "1"
            return str(max(int(k) for k in table.keys()) + 1)
        
        def get_user_from_token(token: str, tokens_data: Dict[str, Any]) -> Optional[str]:
            """Encode token and find associated user_id"""
            try:
                encoded_token = base64.b64encode(token.encode('utf-8')).decode('utf-8')
                for token_info in tokens_data.values():
                    if token_info.get("token_encoded") == encoded_token:
                        return token_info.get("user_id")
                return None
            except:
                return None
        
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        # Validate review_state
        if review_state not in ["pending", "approved", "changes_requested", "commented", "dismissed"]:
            return json.dumps({
                "success": False,
                "error": f"Invalid review_state '{review_state}'"
            })
        
        repositories = data.get("repositories", {})
        pull_requests = data.get("pull_requests", {})
        pull_request_reviews = data.get("pull_request_reviews", {})
        users = data.get("users", {})
        access_tokens = data.get("access_tokens", {})
        repository_collaborators = data.get("repository_collaborators", {})
        organization_members = data.get("organization_members", {})
        
        # Validate access token AND get Reviewer ID
        requesting_user_id = get_user_from_token(access_token, access_tokens)
        if not requesting_user_id:
            return json.dumps({
                "success": False,
                "error": "Invalid or expired access token"
            })
            
        reviewer_id = requesting_user_id
        
        # Check if pull request exists
        if pull_request_id not in pull_requests:
            return json.dumps({
                "success": False,
                "error": f"Pull request with ID '{pull_request_id}' not found"
            })
            
        pull_request = pull_requests[pull_request_id]
        repository_id = pull_request.get("repository_id")
        
        # Check if repository exists
        if repository_id not in repositories:
             return json.dumps({
                "success": False,
                "error": f"Repository with ID '{repository_id}' not found"
            })
            
        repository = repositories[repository_id]
        
        # --- PERMISSION CHECK (Read Access) ---
        # User needs at least READ access to review a PR
        has_access = False
        
        # 1. Public repositories are accessible to everyone
        if repository.get("visibility") == "public":
            has_access = True
            
        # 2. Check if user is the Owner
        if not has_access:
            if repository.get("owner_type") == "user" and repository.get("owner_id") == requesting_user_id:
                has_access = True
                
        # 3. Check if user is a Collaborator (Read, Write, or Admin)
        if not has_access:
            for collab in repository_collaborators.values():
                if (collab.get("repository_id") == repository_id and
                    collab.get("user_id") == requesting_user_id and
                    collab.get("status") == "active"):
                    # Any permission level (read/write/admin) allows viewing/reviewing
                    has_access = True
                    break
        
        # 4. Check if user is an Organization Member
        if not has_access and repository.get("owner_type") == "organization":
            for membership in organization_members.values():
                if (membership.get("organization_id") == repository.get("owner_id") and
                    membership.get("user_id") == requesting_user_id and
                    membership.get("status") == "active"):
                    has_access = True
                    break
        
        if not has_access:
            return json.dumps({
                "success": False,
                "error": "Insufficient permissions. You do not have access to this repository."
            })
        # --------------------------------------

        # Prevent Self-Review
        if pull_request.get("author_id") == reviewer_id:
             return json.dumps({
                "success": False,
                "error": "You cannot review your own pull request."
            })

        timestamp = "2026-01-01T23:59:00"
        new_review_id = generate_id(pull_request_reviews)
        
        new_review = {
            "review_id": new_review_id,
            "pull_request_id": pull_request_id,
            "reviewer_id": reviewer_id,
            "review_state": review_state,
            "review_body": review_body,
            "submitted_at": timestamp,
            "created_at": timestamp
        }
        
        pull_request_reviews[new_review_id] = new_review
        
        return json.dumps({
            "success": True,
            "review_id": new_review_id,
            "review_data": new_review
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "submit_pr_review",
                "description": "Submits a review for a pull request.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "Access token for authentication (required)"
                        },
                        "pull_request_id": {
                            "type": "string",
                            "description": "Pull request ID (required)"
                        },
                        "review_state": {
                            "type": "string",
                            "description": "Review state. Allowed values: 'pending', 'approved', 'changes_requested', 'commented', 'dismissed' (required)",
                            "enum": ["pending", "approved", "changes_requested", "commented", "dismissed"]
                        },
                        "review_body": {
                            "type": "string",
                            "description": "Review body text (optional)"
                        }
                    },
                    "required": ["access_token", "pull_request_id", "review_state"]
                }
            }
        }
import json
from typing import Any, Dict
from tau_bench.envs.tool import Tool


class TransferToHuman(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        summary: str,
    ) -> str:
        return json.dumps("Transfer successful")

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "transfer_to_human",
                "description": "Transfers the user to a human agent, with a summary of the user's issue. Only transfer if the user explicitly asks for a human agent, or if the user's issue cannot be resolved by the agent with the available tools.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "summary": {
                            "type": "string",
                            "description": "A summary of the user's issue.",
                        },
                    },
                    "required": [
                        "summary",
                    ],
                },
            },
        }import json
import base64
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool

class UpdateIssues(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        repository_id: str,
        title: str,
        author_id: str,
        issue_id: Optional[str] = None,
        description: Optional[str] = None,
        assignee_id: Optional[str] = None,
        status: Optional[str] = None,
        priority: Optional[str] = None,
        issue_type: Optional[str] = None
    ) -> str:
        def generate_id(table: Dict[str, Any]) -> str:
            if not table:
                return "1"
            return str(max(int(k) for k in table.keys()) + 1)

        timestamp = "2026-01-01T23:59:00"

        try:
            encoded_input_token = base64.b64encode(access_token.encode('utf-8')).decode('utf-8')
        except Exception:
            return json.dumps({"error": "Failed to process access token"})

        tokens = data.get("access_tokens", {})
        valid_token = False

        for token in tokens.values():
            if token.get("token_encoded") == encoded_input_token and token.get("status") == "active":
                if token.get("expires_at") > timestamp:
                    valid_token = True
                    break
        
        if not valid_token:
            return json.dumps({"error": "Invalid or expired access token"})

        issues = data.get("issues", {})
        repositories = data.get("repositories", {})
        users = data.get("users", {})

        # Validation
        if repository_id not in repositories:
            return json.dumps({"error": f"Repository {repository_id} not found"})
        if author_id not in users:
            return json.dumps({"error": f"Author {author_id} not found"})
        if assignee_id and assignee_id not in users:
            return json.dumps({"error": f"Assignee {assignee_id} not found"})

        # Correction: Updated status to user_status enum as requested
        valid_statuses = ['active', 'suspended', 'deleted']
        if status and status not in valid_statuses:
            return json.dumps({"error": f"Invalid status. Must be one of: {', '.join(valid_statuses)}"})

        # Correction: Removed 'critical'
        valid_priorities = ['low', 'medium', 'high']
        if priority and priority not in valid_priorities:
            return json.dumps({"error": f"Invalid priority. Must be one of: {', '.join(valid_priorities)}"})

        # Correction: Updated 'documentation' to 'doc' and removed others
        valid_types = ['bug', 'feature', 'doc']
        if issue_type and issue_type not in valid_types:
            return json.dumps({"error": f"Invalid issue_type. Must be one of: {', '.join(valid_types)}"})

        # Update or Create
        if issue_id:
            if issue_id not in issues:
                return json.dumps({"error": f"Issue {issue_id} not found"})

            issue = issues[issue_id]
            # Title is required in signature, so it overwrites.
            issue["title"] = title
            
            # Only update optional fields if they are explicitly provided
            if description is not None:
                issue["description"] = description
            if assignee_id is not None:
                issue["assignee_id"] = assignee_id
            if priority is not None:
                issue["priority"] = priority
            if issue_type is not None:
                issue["issue_type"] = issue_type
            
            if status is not None:
                issue["status"] = status
                # Note: closed_at logic removed as 'closed' is no longer a valid status
                if status == 'deleted': 
                     issue["closed_at"] = timestamp # Optional: Treating deleted as closed for logic continuity

            issue["updated_at"] = timestamp
            issues[issue_id] = issue
            return json.dumps(issue)

        else:
            # Create
            new_id = generate_id(issues)

            # Correction: Explicit int conversion for issue_number calculation
            repo_issue_numbers = [int(i["issue_number"]) for i in issues.values() if i["repository_id"] == repository_id]
            next_number = max(repo_issue_numbers) + 1 if repo_issue_numbers else 1

            # Apply defaults for creation
            final_status = status if status is not None else 'active'
            final_type = issue_type if issue_type is not None else 'bug'

            new_issue = {
                "issue_id": new_id,
                "repository_id": repository_id,
                "issue_number": int(next_number), # Explicit cast
                "title": title,
                "description": description,
                "author_id": author_id,
                "assignee_id": assignee_id,
                "status": final_status,
                "priority": priority,
                "issue_type": final_type,
                "created_at": timestamp,
                "updated_at": timestamp,
                "closed_at": None
            }
            issues[new_id] = new_issue
            return json.dumps(new_issue)

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "update_issues",
                "description": "Creates a new issue or updates an existing one.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "The access token for authentication."
                        },
                        "issue_id": {
                            "type": "string",
                            "description": "The ID of the issue. If provided, updates existing issue; otherwise creates new (optional)"
                        },
                        "repository_id": {
                            "type": "string",
                            "description": "The ID of the repository"
                        },
                        "title": {
                            "type": "string",
                            "description": "The title of the issue"
                        },
                        "author_id": {
                            "type": "string",
                            "description": "The user ID of the author"
                        },
                        "description": {
                            "type": "string",
                            "description": "The description of the issue (optional)"
                        },
                        "assignee_id": {
                            "type": "string",
                            "description": "The user ID of the assignee (optional)"
                        },
                        "status": {
                            "type": "string",
                            "description": "Status of the issue. Allowed values: 'active', 'suspended', 'deleted'. Default: 'active' (optional)",
                            "enum": ["active", "suspended", "deleted"]
                        },
                        "priority": {
                            "type": "string",
                            "description": "Priority level. Allowed values: 'low', 'medium', 'high' (optional)",
                            "enum": ["low", "medium", "high"]
                        },
                        "issue_type": {
                            "type": "string",
                            "description": "Type of issue. Allowed values: 'bug', 'feature', 'doc'. Default: 'bug' (optional)",
                            "enum": ["bug", "feature", "doc"]
                        }
                    },
                    "required": ["access_token", "repository_id", "title", "author_id"]
                }
            }
        }import json
import base64
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool

class UpdatePullRequest(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        pull_request_id: str,
        title: Optional[str] = None,
        description: Optional[str] = None,
        status: Optional[str] = None,
        merged_by: Optional[str] = None
    ) -> str:
        timestamp = "2026-01-01T23:59:00"

        try:
            encoded_input_token = base64.b64encode(access_token.encode('utf-8')).decode('utf-8')
        except Exception:
            return json.dumps({"error": "Failed to process access token"})

        tokens = data.get("access_tokens", {})
        valid_token = False
        for token in tokens.values():
            if token.get("token_encoded") == encoded_input_token and token.get("status") == "active":
                if token.get("expires_at") > timestamp:
                    valid_token = True
                    break

        if not valid_token:
            return json.dumps({"error": "Invalid or expired access token"})

        pull_requests = data.get("pull_requests", {})
        users = data.get("users", {})

        if pull_request_id not in pull_requests:
            return json.dumps({"error": f"Pull request with ID {pull_request_id} not found"})

        pr = pull_requests[pull_request_id]

        valid_statuses = ['open', 'closed', 'merged', 'draft']
        if status and status not in valid_statuses:
            return json.dumps({"error": f"Invalid status. Must be one of: {', '.join(valid_statuses)}"})

        if status == 'merged':
            if not merged_by:
                if not pr.get("merged_by"):
                    return json.dumps({"error": "merged_by user_id is required when setting status to merged"})
            else:
                if merged_by not in users:
                    return json.dumps({"error": f"User {merged_by} (merged_by) not found"})

        if title is not None:
            pr["title"] = title
        if description is not None:
            pr["description"] = description

        if status is not None:
            if status == 'merged':
                pr["merged_at"] = timestamp
                pr["closed_at"] = timestamp
                if merged_by:
                    pr["merged_by"] = merged_by
            elif status == 'closed':
                pr["closed_at"] = timestamp
                pr["merged_at"] = None
                pr["merged_by"] = None
            elif status == 'open':
                pr["closed_at"] = None
                pr["merged_at"] = None
                pr["merged_by"] = None

            pr["status"] = status

        pr["updated_at"] = timestamp
        pull_requests[pull_request_id] = pr

        return json.dumps(pr)

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "update_pull_request",
                "description": "Updates details of an existing pull request.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "The access token for authentication."
                        },
                        "pull_request_id": {
                            "type": "string",
                            "description": "The unique identifier of the pull request."
                        },
                        "title": {
                            "type": "string",
                            "description": "The new title of the pull request (optional)"
                        },
                        "description": {
                            "type": "string",
                            "description": "The new description of the pull request (optional)"
                        },
                        "status": {
                            "type": "string",
                            "description": "The new status of the pull request. Allowed values: 'open', 'closed', 'merged', 'draft' (optional)",
                            "enum": ["open", "closed", "merged", "draft"]
                        },
                        "merged_by": {
                            "type": "string",
                            "description": "The user ID of the person merging the pull request. Required if status is set to 'merged' (optional)"
                        }
                    },
                    "required": ["access_token", "pull_request_id"]
                }
            }
        }import json
import base64
from typing import Any, Dict
from tau_bench.envs.tool import Tool


class UpdateRepositoryPermissions(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        repository_id: str,
        user_id: str,
        permission_level: str
    ) -> str:
        def generate_id(table: Dict[str, Any]) -> str:
            if not table:
                return "1"
            return str(max(int(k) for k in table.keys()) + 1)
        
        def get_user_from_token(token: str, tokens_data: Dict[str, Any]) -> str:
            """Encode token and find associated user_id"""
            try:
                # Encode token to base64 UTF-8
                encoded_token = base64.b64encode(token.encode('utf-8')).decode('utf-8')
                # Find token in access_tokens by comparing with token_encoded
                for token_info in tokens_data.values():
                    if token_info.get("token_encoded") == encoded_token:
                        return token_info.get("user_id")
                return None
            except:
                return None
        
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        repositories = data.get("repositories", {})
        repository_collaborators = data.get("repository_collaborators", {})
        access_tokens = data.get("access_tokens", {})
        users = data.get("users", {})
        organization_members = data.get("organization_members", {})
        
        # Validate access token and get requesting user_id
        requesting_user_id = get_user_from_token(access_token, access_tokens)
        if not requesting_user_id:
            return json.dumps({
                "success": False,
                "error": "Invalid or expired access token"
            })
        
        # Check if repository exists
        if repository_id not in repositories:
            return json.dumps({
                "success": False,
                "error": f"Repository with ID '{repository_id}' not found"
            })
        
        # Check if target user exists
        if user_id not in users:
            return json.dumps({
                "success": False,
                "error": f"User with ID '{user_id}' not found"
            })
        
        # Correction: Strict validation for permission_level enum
        valid_permissions = ["read", "write", "admin"]
        if permission_level not in valid_permissions:
            return json.dumps({
                "success": False,
                "error": f"Invalid permission_level '{permission_level}'. Must be one of: {', '.join(valid_permissions)}"
            })
        
        repo = repositories[repository_id]
        owner_type = repo.get("owner_type")
        owner_id = repo.get("owner_id")
        
        # Check if requesting user has admin permissions
        has_admin = False
        
        # Check if requesting user is the owner
        if owner_type == "user" and owner_id == requesting_user_id:
            has_admin = True
        
        # Check if requesting user is organization owner
        if owner_type == "organization" and not has_admin:
            for membership in organization_members.values():
                if (membership.get("organization_id") == owner_id and 
                    membership.get("user_id") == requesting_user_id and
                    membership.get("status") == "active" and
                    membership.get("role") == "owner"):
                    has_admin = True
                    break
        
        # Check if requesting user is collaborator with admin permissions
        if not has_admin:
            for collab in repository_collaborators.values():
                if (collab.get("repository_id") == repository_id and
                    collab.get("user_id") == requesting_user_id and
                    collab.get("status") == "active" and
                    collab.get("permission_level") == "admin"):
                    has_admin = True
                    break
        
        if not has_admin:
            return json.dumps({
                "success": False,
                "error": "Insufficient permissions. Only repository admins can manage collaborators"
            })
        
        timestamp = "2026-01-01T23:59:00"
        
        # Check if user is already a collaborator
        existing_collab_id = None
        for collab_id, collab in repository_collaborators.items():
            if (collab.get("repository_id") == repository_id and
                collab.get("user_id") == user_id):
                existing_collab_id = collab_id
                break
        
        # Update existing collaborator
        if existing_collab_id:
            collab = repository_collaborators[existing_collab_id]
            collab["permission_level"] = permission_level
            collab["status"] = "active"
            
            return json.dumps({
                "success": True,
                "action": "update",
                "repository_id": repository_id,
                "user_id": user_id,
                "permission_level": permission_level,
                "collaborator_id": existing_collab_id,
                "collaborator_data": collab
            })
        
        # Add new collaborator
        else:
            new_collab_id = generate_id(repository_collaborators)
            new_collab = {
                "collaborator_id": new_collab_id,
                "repository_id": repository_id,
                "user_id": user_id,
                "permission_level": permission_level,
                "status": "active",
                "added_at": timestamp
            }
            
            repository_collaborators[new_collab_id] = new_collab
            
            return json.dumps({
                "success": True,
                "action": "create",
                "repository_id": repository_id,
                "user_id": user_id,
                "permission_level": permission_level,
                "collaborator_id": new_collab_id,
                "collaborator_data": new_collab
            })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "update_repository_permissions",
                "description": "Updates repository permissions for a user (add or update collaborator).",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "Access token for authentication (required)"
                        },
                        "repository_id": {
                            "type": "string",
                            "description": "Repository ID to update permissions for (required)"
                        },
                        "user_id": {
                            "type": "string",
                            "description": "User ID to grant/update permissions for (required)"
                        },
                        "permission_level": {
                            "type": "string",
                            "description": "Permission level to grant. Allowed values: 'read', 'write', 'admin' (required)",
                            "enum": ["read", "write", "admin"]
                        }
                    },
                    "required": ["access_token", "repository_id", "user_id", "permission_level"]
                }
            }
        }import json
import base64
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool

class UpdateWorkflow(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        workflow_id: str,
        workflow_name: Optional[str] = None,
        workflow_path: Optional[str] = None,
        trigger_event: Optional[str] = None,
        status: Optional[str] = None
    ) -> str:
        timestamp = "2026-01-01T23:59:00"

        try:
            encoded_input_token = base64.b64encode(access_token.encode('utf-8')).decode('utf-8')
        except Exception:
            return json.dumps({"error": "Failed to process access token"})

        tokens = data.get("access_tokens", {})
        valid_token = False
        for token in tokens.values():
            if token.get("token_encoded") == encoded_input_token and token.get("status") == "active":
                if token.get("expires_at") > timestamp:
                    valid_token = True
                    break
        
        if not valid_token:
            return json.dumps({"error": "Invalid or expired access token"})

        workflows = data.get("workflows", {})

        if workflow_id not in workflows:
            return json.dumps({"error": f"Workflow {workflow_id} not found"})

        workflow = workflows[workflow_id]

        valid_events = ['push', 'pull_request', 'schedule', 'workflow_dispatch', 'release']
        if trigger_event and trigger_event not in valid_events:
            return json.dumps({"error": f"Invalid trigger_event. Must be one of: {', '.join(valid_events)}"})

        valid_statuses = ['active', 'disabled', 'deleted']
        if status and status not in valid_statuses:
            return json.dumps({"error": f"Invalid status. Must be one of: {', '.join(valid_statuses)}"})

        if workflow_name is not None:
            workflow["workflow_name"] = workflow_name
        if workflow_path is not None:
            workflow["workflow_path"] = workflow_path
        if trigger_event is not None:
            workflow["trigger_event"] = trigger_event
        if status is not None:
            workflow["status"] = status

        workflow["updated_at"] = timestamp
        workflows[workflow_id] = workflow

        return json.dumps(workflow)

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "update_workflow",
                "description": "Updates the configuration of an existing workflow.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "The access token for authentication."
                        },
                        "workflow_id": {
                            "type": "string",
                            "description": "The ID of the workflow to update."
                        },
                        "workflow_name": {
                            "type": "string",
                            "description": "The new name of the workflow (optional)"
                        },
                        "workflow_path": {
                            "type": "string",
                            "description": "The new file path to the workflow definition (optional)"
                        },
                        "trigger_event": {
                            "type": "string",
                            "description": "The event that triggers the workflow. Allowed values: 'push', 'pull_request', 'schedule', 'workflow_dispatch', 'release' (optional)",
                            "enum": ["push", "pull_request", "schedule", "workflow_dispatch", "release"]
                        },
                        "status": {
                            "type": "string",
                            "description": "The new status of the workflow. Allowed values: 'active', 'disabled', 'deleted' (optional)",
                            "enum": ["active", "disabled", "deleted"]
                        }
                    },
                    "required": ["access_token", "workflow_id"]
                }
            }
        }import json
import base64
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class UpsertComment(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        action: str,
        comment_body: str,
        commentable_type: Optional[str] = None,
        commentable_id: Optional[str] = None,
        comment_id: Optional[str] = None
    ) -> str:
        def generate_id(table: Dict[str, Any]) -> str:
            if not table:
                return "1"
            return str(max(int(k) for k in table.keys()) + 1)
        
        def get_user_from_token(token: str, tokens_data: Dict[str, Any]) -> Optional[str]:
            """Encode token and find associated user_id"""
            try:
                encoded_token = base64.b64encode(token.encode('utf-8')).decode('utf-8')
                for token_info in tokens_data.values():
                    if token_info.get("token_encoded") == encoded_token:
                        return token_info.get("user_id")
                return None
            except:
                return None
        
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })

        # Validate action
        if action not in ["create", "update"]:
            return json.dumps({
                "success": False,
                "error": f"Invalid action '{action}'. Must be 'create' or 'update'"
            })
        
        comments = data.get("comments", {})
        issues = data.get("issues", {})
        pull_requests = data.get("pull_requests", {})
        repositories = data.get("repositories", {})
        users = data.get("users", {})
        access_tokens = data.get("access_tokens", {})
        repository_collaborators = data.get("repository_collaborators", {})
        organization_members = data.get("organization_members", {})
        
        # Validate access token
        requesting_user_id = get_user_from_token(access_token, access_tokens)
        if not requesting_user_id:
            return json.dumps({
                "success": False,
                "error": "Invalid or expired access token"
            })
            
        author_id = requesting_user_id
        timestamp = "2026-01-01T23:59:00"

        # --- UPDATE LOGIC ---
        if action == "update":
            if not comment_id:
                return json.dumps({
                    "success": False,
                    "error": "comment_id is required for update action"
                })
            
            if comment_id not in comments:
                return json.dumps({
                    "success": False,
                    "error": f"Comment with ID '{comment_id}' not found"
                })
            
            comment = comments[comment_id]
            
            # Security Check: Ownership
            if comment.get("author_id") != author_id:
                return json.dumps({
                    "success": False,
                    "error": "Permission denied. You can only edit your own comments."
                })
                
            comment["comment_body"] = comment_body
            comment["updated_at"] = timestamp
            
            return json.dumps({
                "success": True,
                "action": "update",
                "comment_id": comment_id,
                "comment_data": comment
            })

        # --- CREATE LOGIC ---
        elif action == "create":
            if not commentable_type or not commentable_id:
                return json.dumps({
                    "success": False,
                    "error": "commentable_type and commentable_id are required for create action"
                })

            if commentable_type not in ["issue", "pull_request"]:
                return json.dumps({
                    "success": False,
                    "error": f"Invalid commentable_type '{commentable_type}'"
                })

            # Check if entity exists and get Repository ID
            repository_id = None
            
            if commentable_type == "issue":
                if commentable_id not in issues:
                    return json.dumps({"success": False, "error": f"Issue '{commentable_id}' not found"})
                repository_id = issues[commentable_id].get("repository_id")
            else:
                if commentable_id not in pull_requests:
                    return json.dumps({"success": False, "error": f"Pull Request '{commentable_id}' not found"})
                repository_id = pull_requests[commentable_id].get("repository_id")
            
            # Verify Repository exists
            if repository_id not in repositories:
                 return json.dumps({"success": False, "error": f"Repository '{repository_id}' not found"})
            
            repository = repositories[repository_id]

            # --- PERMISSION CHECK (Read Access) ---
            # To comment, you generally need Read access. 
            has_access = False
            
            # 1. Public repositories
            if repository.get("visibility") == "public":
                has_access = True
            
            # 2. Owner
            if not has_access and repository.get("owner_type") == "user" and repository.get("owner_id") == requesting_user_id:
                has_access = True
                
            # 3. Collaborator
            if not has_access:
                for collab in repository_collaborators.values():
                    if (collab.get("repository_id") == repository_id and
                        collab.get("user_id") == requesting_user_id and
                        collab.get("status") == "active"):
                        has_access = True
                        break
            
            # 4. Organization Member
            if not has_access and repository.get("owner_type") == "organization":
                for membership in organization_members.values():
                    if (membership.get("organization_id") == repository.get("owner_id") and
                        membership.get("user_id") == requesting_user_id and
                        membership.get("status") == "active"):
                        has_access = True
                        break
            
            if not has_access:
                return json.dumps({
                    "success": False,
                    "error": "Insufficient permissions. You do not have access to this repository."
                })
            # --------------------------------------
            
            new_comment_id = generate_id(comments)
            new_comment = {
                "comment_id": new_comment_id,
                "commentable_type": commentable_type,
                "commentable_id": commentable_id,
                "author_id": author_id,
                "comment_body": comment_body,
                "created_at": timestamp,
                "updated_at": timestamp
            }
            comments[new_comment_id] = new_comment
            
            return json.dumps({
                "success": True,
                "action": "create",
                "comment_id": new_comment_id,
                "comment_data": new_comment
            })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "upsert_comment",
                "description": "Creates or updates a comment.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "action": {
                            "type": "string",
                            "description": "Action to perform. Allowed values: 'create', 'update' (required)",
                            "enum": ["create", "update"]
                        },
                        "access_token": {
                            "type": "string",
                            "description": "Access token for authentication (required)"
                        },
                        "comment_body": {
                            "type": "string",
                            "description": "The text content of the comment (required)"
                        },
                        "commentable_type": {
                            "type": "string",
                            "description": "Type of entity (required for 'create'). Allowed values: 'issue', 'pull_request'",
                            "enum": ["issue", "pull_request"]
                        },
                        "commentable_id": {
                            "type": "string",
                            "description": "ID of the issue/PR (required for 'create')"
                        },
                        "comment_id": {
                            "type": "string",
                            "description": "ID of the comment to update (required for 'update')"
                        }
                    },
                    "required": ["action", "access_token", "comment_body"]
                }
            }
        }
import json
import base64
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class UpsertFileDirectory(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        action: str,
        access_token: str,
        repository_id: str,
        branch_id: str,
        item_type: str,
        file_name: Optional[str] = None,
        directory_path: Optional[str] = None,
        parent_directory_id: Optional[str] = None,
        content: Optional[str] = None,
        encoding: Optional[str] = None,
        commit_message: Optional[str] = None,
        author_id: Optional[str] = None,
        language: Optional[str] = None,
        is_binary: Optional[bool] = None,
        file_id: Optional[str] = None,
        directory_id: Optional[str] = None
    ) -> str:
        def generate_id(table: Dict[str, Any]) -> str:
            if not table:
                return "1"
            return str(max(int(k) for k in table.keys()) + 1)
        
        def get_user_from_token(token: str, tokens_data: Dict[str, Any]) -> Optional[str]:
            """Encode token and find associated user_id"""
            try:
                encoded_token = base64.b64encode(token.encode('utf-8')).decode('utf-8')
                for token_info in tokens_data.values():
                    if token_info.get("token_encoded") == encoded_token:
                        return token_info.get("user_id")
                return None
            except:
                return None
        
        def get_latest_content_entry(f_id: str, f_contents: Dict[str, Any]) -> Optional[Dict[str, Any]]:
            """Finds the most recent content entry for a file to support carry-over."""
            entries = [v for v in f_contents.values() if v.get("file_id") == f_id]
            if not entries:
                return None
            # Assuming higher content_id means newer
            return max(entries, key=lambda x: int(x.get("content_id", 0)))
        
        # Validate action
        if action not in ["create", "update"]:
            return json.dumps({
                "success": False,
                "error": f"Invalid action '{action}'. Must be 'create' or 'update'"
            })
        
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        # Validate item_type
        if item_type not in ["file", "directory"]:
            return json.dumps({
                "success": False,
                "error": f"Invalid item_type '{item_type}'. Must be 'file' or 'directory'"
            })
        
        repositories = data.get("repositories", {})
        branches = data.get("branches", {})
        files = data.get("files", {})
        directories = data.get("directories", {})
        commits = data.get("commits", {})
        file_contents = data.get("file_contents", {})
        access_tokens = data.get("access_tokens", {})
        repository_collaborators = data.get("repository_collaborators", {})
        organization_members = data.get("organization_members", {})
        users = data.get("users", {})
        
        # Validate access token
        requesting_user_id = get_user_from_token(access_token, access_tokens)
        if not requesting_user_id:
            return json.dumps({
                "success": False,
                "error": "Invalid or expired access token"
            })
        
        # Check if repository exists
        if repository_id not in repositories:
            return json.dumps({
                "success": False,
                "error": f"Repository with ID '{repository_id}' not found"
            })
        
        # Check if branch exists
        if branch_id not in branches:
            return json.dumps({
                "success": False,
                "error": f"Branch with ID '{branch_id}' not found"
            })
        
        # Validate branch belongs to repository
        branch = branches[branch_id]
        if branch.get("repository_id") != repository_id:
            return json.dumps({
                "success": False,
                "error": f"Branch with ID '{branch_id}' does not belong to repository '{repository_id}'"
            })
        
        # Validate author_id if provided
        if author_id and author_id not in users:
            return json.dumps({
                "success": False,
                "error": f"Author with ID '{author_id}' not found"
            })
        
        repository = repositories[repository_id]
        owner_id = repository.get("owner_id")
        owner_type = repository.get("owner_type")
        
        # Check if user has permission to modify files/directories
        has_permission = False
        
        # Check if user is the owner
        if owner_type == "user" and owner_id == requesting_user_id:
            has_permission = True
        
        # Check if user is a collaborator with write or admin access
        if not has_permission:
            for collab in repository_collaborators.values():
                if (collab.get("repository_id") == repository_id and
                    collab.get("user_id") == requesting_user_id and
                    collab.get("permission_level") in ["write", "admin"] and
                    collab.get("status") == "active"):
                    has_permission = True
                    break
        
        # Check if repository is owned by an organization and user is a member
        if not has_permission and owner_type == "organization":
            for membership in organization_members.values():
                if (membership.get("organization_id") == owner_id and
                    membership.get("user_id") == requesting_user_id and
                    membership.get("status") == "active"):
                    has_permission = True
                    break
        
        if not has_permission:
            return json.dumps({
                "success": False,
                "error": "Insufficient permissions. You must have write access to this repository"
            })
        
        timestamp = "2026-01-01T23:59:00"
        
        # Handle file operations
        if item_type == "file":
            # Validate file_name is provided for create
            if action == "create" and not file_name:
                return json.dumps({
                    "success": False,
                    "error": "file_name is required for file creation"
                })
            
            # Validate encoding if provided
            if encoding and encoding not in ["utf-8", "base64", "binary"]:
                return json.dumps({
                    "success": False,
                    "error": f"Invalid encoding '{encoding}'. Must be 'utf-8', 'base64', or 'binary'"
                })
            
            if action == "update":
                # file_id is required for update
                if not file_id:
                    return json.dumps({
                        "success": False,
                        "error": "file_id is required for update action"
                    })
                
                if file_id not in files:
                    return json.dumps({
                        "success": False,
                        "error": f"File with ID '{file_id}' not found"
                    })
                
                file_obj = files[file_id]
                
                # Validate file belongs to the repository and branch
                if file_obj.get("repository_id") != repository_id:
                    return json.dumps({
                        "success": False,
                        "error": f"File does not belong to repository '{repository_id}'"
                    })
                if file_obj.get("branch_id") != branch_id:
                    return json.dumps({
                        "success": False,
                        "error": f"File does not belong to branch '{branch_id}'"
                    })
                
                # Check if this is a delete operation (no parameters except file_id)
                is_delete = (content is None and file_name is None and parent_directory_id is None and 
                             language is None and is_binary is None)
                
                if is_delete:
                    # DELETE operation
                    # Get the branch's current commit as parent
                    parent_commit_sha = branch.get("commit_sha")
                    parent_commit_id = None
                    
                    if parent_commit_sha:
                        for cid, commit in commits.items():
                            if commit.get("commit_sha") == parent_commit_sha:
                                parent_commit_id = cid
                                break
                    
                    # Create commit for the deletion
                    commit_author = author_id if author_id else requesting_user_id
                    new_commit_id = generate_id(commits)
                    new_commit_sha = f"commit_{new_commit_id}"
                    
                    new_commit = {
                        "commit_id": new_commit_id,
                        "repository_id": repository_id,
                        "commit_sha": new_commit_sha,
                        "author_id": commit_author,
                        "committer_id": commit_author,
                        "message": commit_message if commit_message else f"Delete {file_obj.get('file_name')}",
                        "parent_commit_id": parent_commit_id,
                        "committed_at": timestamp,
                        "created_at": timestamp
                    }
                    commits[new_commit_id] = new_commit
                    
                    # Update branch to point to new commit
                    branch["commit_sha"] = new_commit_sha
                    branch["updated_at"] = timestamp
                    
                    # Delete the file
                    deleted_file = files.pop(file_id)
                    
                    return json.dumps({
                        "success": True,
                        "action": "delete",
                        "item_type": "file",
                        "file_id": file_id,
                        "commit_id": new_commit_id,
                        "deleted_file": deleted_file
                    })
                
                # Check if this is a move operation (file_name or parent_directory_id changed)
                current_file_name = file_obj.get("file_name")
                current_parent_id = file_obj.get("directory_id")
                
                new_file_name = file_name if file_name is not None else current_file_name
                new_parent_id = parent_directory_id if parent_directory_id is not None else current_parent_id
                
                is_move = (new_file_name != current_file_name or new_parent_id != current_parent_id)
                
                if is_move:
                    # MOVE operation (could also include content update)
                    # Validate new parent_directory_id if provided
                    if new_parent_id:
                        if new_parent_id not in directories:
                            return json.dumps({
                                "success": False,
                                "error": f"Parent directory with ID '{new_parent_id}' not found"
                            })
                        
                        parent_dir = directories[new_parent_id]
                        if parent_dir.get("repository_id") != repository_id:
                            return json.dumps({
                                "success": False,
                                "error": f"Parent directory does not belong to repository '{repository_id}'"
                            })
                        if parent_dir.get("branch_id") != branch_id:
                            return json.dumps({
                                "success": False,
                                "error": f"Parent directory does not belong to branch '{branch_id}'"
                            })
                    
                    # Construct new file_path
                    if new_parent_id:
                        parent_dir = directories[new_parent_id]
                        dir_path = parent_dir.get("directory_path")
                        new_file_path = f"{dir_path}/{new_file_name}"
                    else:
                        # Root level file
                        new_file_path = new_file_name
                    
                    # Check if file already exists at new location
                    for existing_file_id, existing_file in files.items():
                        if (existing_file_id != file_id and
                            existing_file.get("repository_id") == repository_id and
                            existing_file.get("branch_id") == branch_id and
                            existing_file.get("file_path") == new_file_path):
                            return json.dumps({
                                "success": False,
                                "error": f"File already exists at path '{new_file_path}'"
                            })
                    
                    # Get the branch's current commit as parent
                    parent_commit_sha = branch.get("commit_sha")
                    parent_commit_id = None
                    
                    if parent_commit_sha:
                        for cid, commit in commits.items():
                            if commit.get("commit_sha") == parent_commit_sha:
                                parent_commit_id = cid
                                break
                    
                    # Create commit for the move
                    commit_author = author_id if author_id else requesting_user_id
                    new_commit_id = generate_id(commits)
                    new_commit_sha = f"commit_{new_commit_id}"
                    
                    old_path = file_obj.get("file_path")
                    new_commit = {
                        "commit_id": new_commit_id,
                        "repository_id": repository_id,
                        "commit_sha": new_commit_sha,
                        "author_id": commit_author,
                        "committer_id": commit_author,
                        "message": commit_message if commit_message else f"Move {new_file_name} from {old_path} to {new_file_path}",
                        "parent_commit_id": parent_commit_id,
                        "committed_at": timestamp,
                        "created_at": timestamp
                    }
                    commits[new_commit_id] = new_commit
                    
                    # Update branch to point to new commit
                    branch["commit_sha"] = new_commit_sha
                    branch["updated_at"] = timestamp
                    
                    # Update file location
                    file_obj["file_path"] = new_file_path
                    file_obj["file_name"] = new_file_name
                    file_obj["directory_id"] = new_parent_id
                    if language is not None:
                        file_obj["language"] = language
                    if is_binary is not None:
                        file_obj["is_binary"] = is_binary
                    file_obj["last_modified_at"] = timestamp
                    file_obj["last_commit_id"] = new_commit_id
                    file_obj["updated_at"] = timestamp
                    
                    # --- UPDATED: Ensure content entry exists for move ---
                    final_content = content
                    final_encoding = encoding if encoding else "utf-8"
                    
                    # If no new content provided, try to carry over previous content
                    if final_content is None:
                        latest_entry = get_latest_content_entry(file_id, file_contents)
                        if latest_entry:
                            final_content = latest_entry["content"]
                            final_encoding = latest_entry["encoding"]
                        else:
                            final_content = "" # Fallback for empty files
                    
                    new_content_id = generate_id(file_contents)
                    new_content = {
                        "content_id": new_content_id,
                        "file_id": file_id,
                        "commit_id": new_commit_id,
                        "content": final_content,
                        "encoding": final_encoding,
                        "created_at": timestamp
                    }
                    file_contents[new_content_id] = new_content
                    # ---------------------------------------------------
                    
                    return json.dumps({
                        "success": True,
                        "action": "move",
                        "item_type": "file",
                        "file_id": file_id,
                        "commit_id": new_commit_id,
                        "old_path": old_path,
                        "new_path": new_file_path,
                        "file_data": file_obj
                    })
                
                # Regular UPDATE operation (content/metadata only, no move)
                # Get the branch's current commit as parent
                parent_commit_sha = branch.get("commit_sha")
                parent_commit_id = None
                
                if parent_commit_sha:
                    for cid, commit in commits.items():
                        if commit.get("commit_sha") == parent_commit_sha:
                            parent_commit_id = cid
                            break
                
                # Create commit for the update
                commit_author = author_id if author_id else requesting_user_id
                new_commit_id = generate_id(commits)
                new_commit_sha = f"commit_{new_commit_id}"
                
                new_commit = {
                    "commit_id": new_commit_id,
                    "repository_id": repository_id,
                    "commit_sha": new_commit_sha,
                    "author_id": commit_author,
                    "committer_id": commit_author,
                    "message": commit_message if commit_message else f"Update {current_file_name}",
                    "parent_commit_id": parent_commit_id,
                    "committed_at": timestamp,
                    "created_at": timestamp
                }
                commits[new_commit_id] = new_commit
                
                # Update branch to point to new commit
                branch["commit_sha"] = new_commit_sha
                branch["updated_at"] = timestamp
                
                # Update file metadata (not location)
                if language is not None:
                    file_obj["language"] = language
                if is_binary is not None:
                    file_obj["is_binary"] = is_binary
                file_obj["last_modified_at"] = timestamp
                file_obj["last_commit_id"] = new_commit_id
                file_obj["updated_at"] = timestamp
                
                # --- UPDATED: Ensure content entry exists for update ---
                final_content = content
                final_encoding = encoding if encoding else "utf-8"
                
                if final_content is None:
                    latest_entry = get_latest_content_entry(file_id, file_contents)
                    if latest_entry:
                        final_content = latest_entry["content"]
                        final_encoding = latest_entry["encoding"]
                    else:
                        final_content = ""
                
                new_content_id = generate_id(file_contents)
                new_content = {
                    "content_id": new_content_id,
                    "file_id": file_id,
                    "commit_id": new_commit_id,
                    "content": final_content,
                    "encoding": final_encoding,
                    "created_at": timestamp
                }
                file_contents[new_content_id] = new_content
                # -----------------------------------------------------
                
                return json.dumps({
                    "success": True,
                    "action": "update",
                    "item_type": "file",
                    "file_id": file_id,
                    "commit_id": new_commit_id,
                    "file_data": file_obj
                })
            
            elif action == "create":
                # Validate parent_directory_id if provided (not null)
                if parent_directory_id:
                    if parent_directory_id not in directories:
                        return json.dumps({
                            "success": False,
                            "error": f"Parent directory with ID '{parent_directory_id}' not found"
                        })
                    
                    parent_dir = directories[parent_directory_id]
                    if parent_dir.get("repository_id") != repository_id:
                        return json.dumps({
                            "success": False,
                            "error": f"Parent directory does not belong to repository '{repository_id}'"
                        })
                    if parent_dir.get("branch_id") != branch_id:
                        return json.dumps({
                            "success": False,
                            "error": f"Parent directory does not belong to branch '{branch_id}'"
                        })
                
                # Construct file_path from parent_directory_id
                if parent_directory_id:
                    parent_dir = directories[parent_directory_id]
                    dir_path = parent_dir.get("directory_path")
                    file_path = f"{dir_path}/{file_name}"
                else:
                    # Root level file (parent_directory_id is None or not provided)
                    file_path = file_name
                
                # Check for duplicate file in same location
                for existing_file in files.values():
                    if (existing_file.get("repository_id") == repository_id and
                        existing_file.get("branch_id") == branch_id and
                        existing_file.get("file_path") == file_path):
                        return json.dumps({
                            "success": False,
                            "error": f"File already exists at path '{file_path}'"
                        })
                
                # Get the branch's current commit as parent
                parent_commit_sha = branch.get("commit_sha")
                parent_commit_id = None
                
                if parent_commit_sha:
                    for cid, commit in commits.items():
                        if commit.get("commit_sha") == parent_commit_sha:
                            parent_commit_id = cid
                            break
                
                # Create commit for the new file
                commit_author = author_id if author_id else requesting_user_id
                new_commit_id = generate_id(commits)
                new_commit_sha = f"commit_{new_commit_id}"
                
                new_commit = {
                    "commit_id": new_commit_id,
                    "repository_id": repository_id,
                    "commit_sha": new_commit_sha,
                    "author_id": commit_author,
                    "committer_id": commit_author,
                    "message": commit_message if commit_message else f"Create {file_name}",
                    "parent_commit_id": parent_commit_id,
                    "committed_at": timestamp,
                    "created_at": timestamp
                }
                commits[new_commit_id] = new_commit
                
                # Update branch to point to new commit
                branch["commit_sha"] = new_commit_sha
                branch["updated_at"] = timestamp
                
                # Create new file
                new_file_id = generate_id(files)
                new_file = {
                    "file_id": new_file_id,
                    "repository_id": repository_id,
                    "branch_id": branch_id,
                    "directory_id": parent_directory_id,
                    "file_path": file_path,
                    "file_name": file_name,
                    "language": language if language else "Unknown",
                    "is_binary": bool(is_binary) if is_binary is not None else False,
                    "last_modified_at": timestamp,
                    "last_commit_id": new_commit_id,
                    "created_at": timestamp,
                    "updated_at": timestamp
                }
                files[new_file_id] = new_file
                
                # Create file content entry
                new_content_id = generate_id(file_contents)
                new_content = {
                    "content_id": new_content_id,
                    "file_id": new_file_id,
                    "commit_id": new_commit_id,
                    "content": content if content is not None else "",
                    "encoding": encoding if encoding else "utf-8",
                    "created_at": timestamp
                }
                file_contents[new_content_id] = new_content
                
                return json.dumps({
                    "success": True,
                    "action": "create",
                    "item_type": "file",
                    "file_id": new_file_id,
                    "commit_id": new_commit_id,
                    "file_data": new_file
                })
        
        # Handle directory operations
        elif item_type == "directory":
            # Validate directory_path is provided for create and update
            if action == "create" and not directory_path:
                return json.dumps({
                    "success": False,
                    "error": "directory_path is required for directory creation"
                })
            
            if action == "update":
                # directory_id is required for update
                if not directory_id:
                    return json.dumps({
                        "success": False,
                        "error": "directory_id is required for update action"
                    })
                
                if directory_id not in directories:
                    return json.dumps({
                        "success": False,
                        "error": f"Directory with ID '{directory_id}' not found"
                    })
                
                dir_obj = directories[directory_id]
                
                # Validate directory belongs to the repository and branch
                if dir_obj.get("repository_id") != repository_id:
                    return json.dumps({
                        "success": False,
                        "error": f"Directory does not belong to repository '{repository_id}'"
                    })
                if dir_obj.get("branch_id") != branch_id:
                    return json.dumps({
                        "success": False,
                        "error": f"Directory does not belong to branch '{branch_id}'"
                    })
                
                # Check if this is a delete operation (directory_path is empty string)
                if directory_path == "":
                    # DELETE operation
                    # Check if directory has any children directories
                    for child_dir in directories.values():
                        if child_dir.get("parent_directory_id") == directory_id:
                            return json.dumps({
                                "success": False,
                                "error": f"Cannot delete directory: it contains subdirectories. Delete child directories first."
                            })
                    
                    # Check if directory has any files
                    for file_obj in files.values():
                        if file_obj.get("directory_id") == directory_id:
                            return json.dumps({
                                "success": False,
                                "error": f"Cannot delete directory: it contains files. Delete or move files first."
                            })
                    
                    # Delete the directory
                    deleted_dir = directories.pop(directory_id)
                    
                    return json.dumps({
                        "success": True,
                        "action": "delete",
                        "item_type": "directory",
                        "directory_id": directory_id,
                        "deleted_directory": deleted_dir
                    })
                
                # MOVE operation (directory_path is provided and not empty)
                if not directory_path:
                    return json.dumps({
                        "success": False,
                        "error": "directory_path is required for directory move operation"
                    })
                
                old_path = dir_obj.get("directory_path")
                
                # Infer parent_directory_id from new directory_path
                inferred_parent_id = None
                if '/' in directory_path:
                    parent_path = '/'.join(directory_path.split('/')[:-1])
                    
                    # Search for parent directory - MUST exist
                    for dir_id, dir_data in directories.items():
                        if (dir_data.get("repository_id") == repository_id and
                            dir_data.get("branch_id") == branch_id and
                            dir_data.get("directory_path") == parent_path):
                            inferred_parent_id = dir_id
                            break
                    
                    # Parent MUST exist
                    if not inferred_parent_id:
                        return json.dumps({
                            "success": False,
                            "error": f"Parent directory path '{parent_path}' does not exist"
                        })
                    
                    # Check if trying to move into itself or its own subdirectory
                    current_check_id = inferred_parent_id
                    while current_check_id:
                        if current_check_id == directory_id:
                            return json.dumps({
                                "success": False,
                                "error": "Cannot move directory into itself or its own subdirectory"
                            })
                        current_check_id = directories.get(current_check_id, {}).get("parent_directory_id")
                
                # Check if directory already exists at new location
                for existing_dir_id, existing_dir in directories.items():
                    if (existing_dir_id != directory_id and
                        existing_dir.get("repository_id") == repository_id and
                        existing_dir.get("branch_id") == branch_id and
                        existing_dir.get("directory_path") == directory_path):
                        return json.dumps({
                            "success": False,
                            "error": f"Directory already exists at path '{directory_path}'"
                        })
                
                # Determine if this is a rename or move
                old_parent_id = dir_obj.get("parent_directory_id")
                if inferred_parent_id == old_parent_id:
                    operation_type = "rename"
                else:
                    operation_type = "move"
                
                # Update directory path and parent
                dir_obj["directory_path"] = directory_path
                dir_obj["parent_directory_id"] = inferred_parent_id
                dir_obj["updated_at"] = timestamp
                
                # Update all child directories and files paths recursively
                def update_child_paths(old_parent_path: str, new_parent_path: str):
                    # Update child directories
                    for child_dir_id, child_dir in directories.items():
                        child_path = child_dir.get("directory_path", "")
                        if child_path.startswith(old_parent_path + "/"):
                            # Replace the old parent path with new parent path
                            new_child_path = child_path.replace(old_parent_path, new_parent_path, 1)
                            child_dir["directory_path"] = new_child_path
                            child_dir["updated_at"] = timestamp
                    
                    # Update files in moved directory and its subdirectories
                    for file_obj in files.values():
                        file_path = file_obj.get("file_path", "")
                        if file_path.startswith(old_parent_path + "/"):
                            new_file_path = file_path.replace(old_parent_path, new_parent_path, 1)
                            file_obj["file_path"] = new_file_path
                            file_obj["updated_at"] = timestamp
                
                update_child_paths(old_path, directory_path)
                
                return json.dumps({
                    "success": True,
                    "action": operation_type,
                    "item_type": "directory",
                    "directory_id": directory_id,
                    "old_path": old_path,
                    "new_path": directory_path,
                    "directory_data": dir_obj
                })
            
            elif action == "create":
                # Infer parent_directory_id from directory_path
                inferred_parent_id = None
                if '/' in directory_path:
                    parent_path = '/'.join(directory_path.split('/')[:-1])
                    
                    # Search for parent directory - MUST exist for non-root directories
                    for dir_id, dir_data in directories.items():
                        if (dir_data.get("repository_id") == repository_id and
                            dir_data.get("branch_id") == branch_id and
                            dir_data.get("directory_path") == parent_path):
                            inferred_parent_id = dir_id
                            break
                    
                    # Parent MUST exist for nested directories
                    if not inferred_parent_id:
                        return json.dumps({
                            "success": False,
                            "error": f"Parent directory path '{parent_path}' does not exist. Create parent directories first."
                        })
                
                # Check for duplicate directory in same location
                for existing_dir in directories.values():
                    if (existing_dir.get("repository_id") == repository_id and
                        existing_dir.get("branch_id") == branch_id and
                        existing_dir.get("directory_path") == directory_path):
                        return json.dumps({
                            "success": False,
                            "error": f"Directory already exists at path '{directory_path}'"
                        })
                
                # Create new directory
                new_dir_id = generate_id(directories)
                new_dir = {
                    "directory_id": new_dir_id,
                    "repository_id": repository_id,
                    "branch_id": branch_id,
                    "directory_path": directory_path,
                    "parent_directory_id": inferred_parent_id,
                    "created_at": timestamp,
                    "updated_at": timestamp
                }
                directories[new_dir_id] = new_dir
                
                return json.dumps({
                    "success": True,
                    "action": "create",
                    "item_type": "directory",
                    "directory_id": new_dir_id,
                    "directory_data": new_dir
                })
        
        return json.dumps({
            "success": False,
            "error": "Unknown error"
        })

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "upsert_file_directory",
                "description": "Creates or updates a file or directory in a repository branch.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "action": {
                            "type": "string",
                            "description": "Action to perform. Allowed values: 'create', 'update' (required)",
                            "enum": ["create", "update"]
                        },
                        "access_token": {
                            "type": "string",
                            "description": "Access token for authentication (will be encoded to base64 UTF-8 and compared with token_encoded) (required)"
                        },
                        "repository_id": {
                            "type": "string",
                            "description": "Repository ID (required)"
                        },
                        "branch_id": {
                            "type": "string",
                            "description": "Branch ID (required)"
                        },
                        "item_type": {
                            "type": "string",
                            "description": "Type of item. Allowed values: 'file', 'directory' (required)",
                            "enum": ["file", "directory"]
                        },
                        "file_name": {
                            "type": "string",
                            "description": "File name only (e.g., 'index.js'). Required for file creation. For move operation, provide new file name. File path will be constructed from parent_directory_id."
                        },
                        "directory_path": {
                            "type": "string",
                            "description": "Full directory path (e.g., 'src/components'). Required for directory creation. For move operation, provide new directory path. For delete operation, provide empty string. Parent directory ID is inferred from this path."
                        },
                        "parent_directory_id": {
                            "type": "string",
                            "description": "Parent directory ID for file operations. Optional - if not provided, file is created at root level. For move operation, provide new parent directory ID."
                        },
                        "content": {
                            "type": "string",
                            "description": "File content (optional, for files only)"
                        },
                        "encoding": {
                            "type": "string",
                            "description": "Content encoding. Allowed values: 'utf-8', 'base64', 'binary' (optional, defaults to 'utf-8')",
                            "enum": ["utf-8", "base64", "binary"]
                        },
                        "commit_message": {
                            "type": "string",
                            "description": "Commit message (optional, for files only). Defaults to 'Update <file_name>' for updates and 'Create <file_name>' for creates in case not provided."
                        },
                        "author_id": {
                            "type": "string",
                            "description": "Author user ID (optional, defaults to authenticated user)"
                        },
                        "language": {
                            "type": "string",
                            "description": "Programming language (optional, for files only)",
                            "enum": [
                                'C', 'C++', 'C#', 'Go', 'Rust', 'Java', 'Kotlin', 'Scala', 'Python', 'Ruby', 'PHP',
                                'JavaScript', 'TypeScript', 'Shell', 'PowerShell', 'Swift', 'Objective-C', 'Dart',
                                'R', 'MATLAB', 'Groovy', 'Perl', 'Lua', 'Haskell', 'Elixir', 'Erlang', 'Julia',
                                'Assembly', 'Fortran', 'COBOL', 'HTML', 'CSS',  'SCSS', 'Less', 'Markdown', 'AsciiDoc',
                                'JSON', 'YAML', 'XML', 'TOML', 'INI', 'CSV', 'Dockerfile', 'Makefile', 'Bash',
                                'Terraform', 'Ansible', 'SQL', 'PLpgSQL', 'Text', 'Binary', 'Unknown'
                            ]
                        },
                        "is_binary": {
                            "type": "boolean",
                            "description": "Whether file is binary. Allowed values: True, False (optional, for files only, defaults to False)"
                        },
                        "file_id": {
                            "type": "string",
                            "description": "File ID (required for update action when item_type='file')"
                        },
                        "directory_id": {
                            "type": "string",
                            "description": "Directory ID (required for update action when item_type='directory')"
                        }
                    },
                    "required": ["action", "access_token", "repository_id", "branch_id", "item_type"]
                }
            }
        }import json
import base64
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class UpsertLabel(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        action: str,
        repository_id: Optional[str] = None,
        label_id: Optional[str] = None,
        label_name: Optional[str] = None,
        color: Optional[str] = None,
        description: Optional[str] = None,
        pr_ids: Optional[str] = None,
        issue_ids: Optional[str] = None
    ) -> str:
        def generate_id(table: Dict[str, Any]) -> str:
            if not table:
                return "1"
            return str(max(int(k) for k in table.keys()) + 1)
        
        def get_user_from_token(token: str, tokens_data: Dict[str, Any]) -> Optional[str]:
            """Encode token and find associated user_id"""
            try:
                encoded_token = base64.b64encode(token.encode('utf-8')).decode('utf-8')
                for token_info in tokens_data.values():
                    if token_info.get("token_encoded") == encoded_token:
                        return token_info.get("user_id")
                return None
            except:
                return None
        
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        # Validate action
        if action not in ["create", "update"]:
            return json.dumps({
                "success": False,
                "error": f"Invalid action '{action}'. Must be 'create' or 'update'"
            })
        
        repositories = data.get("repositories", {})
        labels = data.get("labels", {})
        access_tokens = data.get("access_tokens", {})
        repository_collaborators = data.get("repository_collaborators", {})
        organization_members = data.get("organization_members", {})
        
        # Validate access token
        requesting_user_id = get_user_from_token(access_token, access_tokens)
        if not requesting_user_id:
            return json.dumps({
                "success": False,
                "error": "Invalid or expired access token"
            })
        
        # Validate color format (only if provided)
        if color and (not color.startswith('#') or len(color) != 7):
            return json.dumps({
                "success": False,
                "error": f"Invalid color format '{color}'. Must be hexadecimal format like #445566"
            })

        timestamp = "2026-01-01T23:59:00"

        # --- HELPER: CHECK PERMISSIONS ---
        def check_permissions(repo_id: str, user_id: str) -> bool:
            if repo_id not in repositories:
                return False
            
            repo = repositories[repo_id]
            owner_id = repo.get("owner_id")
            owner_type = repo.get("owner_type")
            
            # 1. Owner
            if owner_type == "user" and owner_id == user_id:
                return True
            
            # 2. Collaborator (Write or Admin)
            for collab in repository_collaborators.values():
                if (collab.get("repository_id") == repo_id and
                    collab.get("user_id") == user_id and
                    collab.get("permission_level") in ["write", "admin"] and
                    collab.get("status") == "active"):
                    return True
            
            # 3. Organization Member
            if owner_type == "organization":
                for membership in organization_members.values():
                    if (membership.get("organization_id") == owner_id and
                        membership.get("user_id") == user_id and
                        membership.get("status") == "active"):
                        return True
            
            return False

        # --- UPDATE LOGIC ---
        if action == "update":
            if not label_id:
                return json.dumps({"success": False, "error": "label_id is required for update action"})
            
            if label_id not in labels:
                return json.dumps({"success": False, "error": f"Label with ID '{label_id}' not found"})
            
            label = labels[label_id]
            current_repo_id = label.get("repository_id")
            
            # Check Permissions
            if not check_permissions(current_repo_id, requesting_user_id):
                 return json.dumps({
                    "success": False,
                    "error": "Insufficient permissions. You must have write access to this repository to manage labels."
                })
            
            # Partial Updates: Only update fields that are provided
            if label_name: 
                label["label_name"] = label_name
            if color: 
                label["color"] = color
            if description is not None: 
                label["description"] = description
            if pr_ids is not None: 
                label["pr_ids"] = pr_ids
            if issue_ids is not None: 
                label["issue_ids"] = issue_ids
            
            return json.dumps({
                "success": True,
                "action": "update",
                "label_id": label_id,
                "label_data": label
            })

        # --- CREATE LOGIC ---
        elif action == "create":
            # Strict validation for Create
            if not repository_id:
                return json.dumps({"success": False, "error": "repository_id is required for create action"})
            if not label_name:
                return json.dumps({"success": False, "error": "label_name is required for create action"})
            if not color:
                return json.dumps({"success": False, "error": "color is required for create action"})
            
            if repository_id not in repositories:
                return json.dumps({"success": False, "error": f"Repository with ID '{repository_id}' not found"})

            # Check Permissions
            if not check_permissions(repository_id, requesting_user_id):
                 return json.dumps({
                    "success": False,
                    "error": "Insufficient permissions. You must have write access to this repository to create labels."
                })

            new_label_id = generate_id(labels)
            new_label = {
                "label_id": new_label_id,
                "repository_id": repository_id,
                "label_name": label_name,
                "color": color,
                "pr_ids": pr_ids,
                "issue_ids": issue_ids,
                "description": description,
                "created_at": timestamp
            }
            labels[new_label_id] = new_label
            
            return json.dumps({
                "success": True,
                "action": "create",
                "label_id": new_label_id,
                "label_data": new_label
            })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "upsert_label",
                "description": "Creates or updates a label in a repository.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "action": {
                            "type": "string",
                            "description": "Action to perform. Allowed values: 'create', 'update' (required)",
                            "enum": ["create", "update"]
                        },
                        "access_token": {
                            "type": "string",
                            "description": "Access token for authentication (required)"
                        },
                        "label_name": {
                            "type": "string",
                            "description": "Label name (required for create, optional for update)"
                        },
                        "color": {
                            "type": "string",
                            "description": "Label color in hexadecimal format (e.g., #445566) (required for create, optional for update)"
                        },
                        "repository_id": {
                            "type": "string",
                            "description": "Repository ID (required for 'create')"
                        },
                        "label_id": {
                            "type": "string",
                            "description": "Label ID (required for 'update')"
                        },
                        "description": {
                            "type": "string",
                            "description": "Label description (optional)"
                        },
                        "pr_ids": {
                            "type": "string",
                            "description": "JSON string array of pull request IDs (e.g., '[\"1\",\"2\"]') (optional)"
                        },
                        "issue_ids": {
                            "type": "string",
                            "description": "JSON string array of issue IDs (e.g., '[\"6\",\"7\"]') (optional)"
                        }
                    },
                    "required": ["action", "access_token"]
                }
            }
        }
import json
import base64
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool

class UpsertRelease(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        access_token: str,
        repository_id: str,
        tag_name: str,
        author_id: str,
        target_type: str,
        target_reference: str,
        release_id: Optional[str] = None,
        release_name: Optional[str] = None,
        description: Optional[str] = None,
        is_draft: Optional[bool] = False,
        is_prerelease: Optional[bool] = False
    ) -> str:
        def generate_id(table: Dict[str, Any]) -> str:
            if not table:
                return "1"
            return str(max(int(k) for k in table.keys()) + 1)

        timestamp = "2026-01-01T23:59:00"

        try:
            encoded_input_token = base64.b64encode(access_token.encode('utf-8')).decode('utf-8')
        except Exception:
            return json.dumps({"error": "Failed to process access token"})

        tokens = data.get("access_tokens", {})
        valid_token = False
        for token in tokens.values():
            if token.get("token_encoded") == encoded_input_token and token.get("status") == "active":
                if token.get("expires_at") > timestamp:
                    valid_token = True
                    break
        
        if not valid_token:
            return json.dumps({"error": "Invalid or expired access token"})

        releases = data.get("releases", {})
        repositories = data.get("repositories", {})
        users = data.get("users", {})

        if repository_id not in repositories:
            return json.dumps({"error": f"Repository {repository_id} not found"})
        
        if author_id not in users:
            return json.dumps({"error": f"User {author_id} not found"})

        # orrection: Strict validation for target_type enum
        valid_targets = ['commit', 'branch']
        if target_type not in valid_targets:
            return json.dumps({"error": f"Invalid target_type. Must be one of: {', '.join(valid_targets)}"})

        if release_id:
            # Update existing
            if release_id not in releases:
                return json.dumps({"error": f"Release {release_id} not found"})
            
            release = releases[release_id]
            # Update fields
            release["tag_name"] = tag_name
            release["author_id"] = author_id
            release["target_type"] = target_type
            release["target_reference"] = target_reference
            release["is_draft"] = bool(is_draft)
            release["is_prerelease"] = bool(is_prerelease)
            
            if release_name is not None:
                release["release_name"] = release_name
            if description is not None:
                release["description"] = description
            
            if not is_draft:
                if not release.get("published_at"):
                    release["published_at"] = timestamp
            else:
                release["published_at"] = None
            
            releases[release_id] = release
            return json.dumps(release)

        else:
            # Create new
            new_id = generate_id(releases)
            new_release = {
                "release_id": new_id,
                "repository_id": repository_id,
                "tag_name": tag_name,
                "release_name": release_name,
                "description": description,
                "author_id": author_id,
                "target_type": target_type,
                "target_reference": target_reference,
                "is_draft": bool(is_draft),
                "is_prerelease": bool(is_prerelease),
                "published_at": timestamp if not is_draft else None,
                "created_at": timestamp
            }
            releases[new_id] = new_release
            return json.dumps(new_release)

    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "upsert_release",
                "description": "Creates a new release or updates an existing one.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "access_token": {
                            "type": "string",
                            "description": "The access token for authentication."
                        },
                        "release_id": {
                            "type": "string",
                            "description": "The ID of the release. If provided, updates the existing release. (optional)"
                        },
                        "repository_id": {
                            "type": "string",
                            "description": "The ID of the repository."
                        },
                        "tag_name": {
                            "type": "string",
                            "description": "The name of the tag."
                        },
                        "author_id": {
                            "type": "string",
                            "description": "The user ID of the author."
                        },
                        "target_type": {
                            "type": "string",
                            "description": "The type of the target. Allowed values: 'commit', 'branch'.",
                            "enum": ["commit", "branch"]
                        },
                        "target_reference": {
                            "type": "string",
                            "description": "The reference to the target (e.g., commit SHA or branch name)."
                        },
                        "release_name": {
                            "type": "string",
                            "description": "The name of the release. (optional)"
                        },
                        "description": {
                            "type": "string",
                            "description": "The description of the release (optional)"
                        },
                        "is_draft": {
                            "type": "boolean",
                            "description": "Whether the release is a draft (True/False). (optional)"
                        },
                        "is_prerelease": {
                            "type": "boolean",
                            "description": "Whether the release is a prerelease (True/False). (optional)"
                        }
                    },
                    "required": ["access_token", "repository_id", "tag_name", "author_id", "target_type", "target_reference"]
                }
            }
        }import json
import base64
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class UpsertRepository(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        action: str,
        access_token: str,
        repository_name: str,
        owner_type: str,
        owner_id: str,
        description: Optional[str] = None,
        visibility: Optional[str] = None,
        default_branch: Optional[str] = None,
        is_template: Optional[bool] = None,
        license_type: Optional[str] = None,
        is_archived: Optional[bool] = None,
        repository_id: Optional[str] = None,
        forks_count: Optional[int] = None,
        stars_count: Optional[int] = None
    ) -> str:
        def generate_id(table: Dict[str, Any]) -> str:
            if not table:
                return "1"
            return str(max(int(k) for k in table.keys()) + 1)
        
        def get_user_from_token(token: str, tokens_data: Dict[str, Any]) -> Optional[str]:
            """Encode token and find associated user_id"""
            try:
                # Encode token to base64 UTF-8
                encoded_token = base64.b64encode(token.encode('utf-8')).decode('utf-8')
                # Find token in access_tokens by comparing with token_encoded
                for token_info in tokens_data.values():
                    if token_info.get("token_encoded") == encoded_token:
                        return token_info.get("user_id")
                return None
            except:
                return None
        
        if action not in ["create", "update"]:
            return json.dumps({
                "success": False,
                "error": f"Invalid action '{action}'. Must be 'create' or 'update'"
            })
        
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        repositories = data.get("repositories", {})
        users = data.get("users", {})
        organizations = data.get("organizations", {})
        access_tokens = data.get("access_tokens", {})
        
        # Validate access token
        requesting_user_id = get_user_from_token(access_token, access_tokens)
        if not requesting_user_id:
            return json.dumps({
                "success": False,
                "error": "Invalid or expired access token"
            })
        
        timestamp = "2026-01-01T23:59:00"
        
        if action == "create":
            # Validate owner exists
            if owner_type == "user":
                if owner_id not in users:
                    return json.dumps({
                        "success": False,
                        "error": f"User with ID '{owner_id}' not found"
                    })
            elif owner_type == "organization":
                if owner_id not in organizations:
                    return json.dumps({
                        "success": False,
                        "error": f"Organization with ID '{owner_id}' not found"
                    })
            else:
                return json.dumps({
                    "success": False,
                    "error": f"Invalid owner_type '{owner_type}'. Must be 'user' or 'organization'"
                })
            
            # Validate visibility
            if visibility and visibility not in ["public", "private", "internal"]:
                return json.dumps({
                    "success": False,
                    "error": f"Invalid visibility '{visibility}'. Must be 'public', 'private', or 'internal'"
                })
            
            # Validate license_type
            if license_type and license_type not in ["MIT", "Apache-2.0", "GPL-3.0", "BSD-3-Clause", "unlicensed", "other"]:
                return json.dumps({
                    "success": False,
                    "error": f"Invalid license_type '{license_type}'. Must be one of: 'MIT', 'Apache-2.0', 'GPL-3.0', 'BSD-3-Clause', 'unlicensed', 'other'"
                })
            
            # Check for duplicate repository name for owner
            for repo in repositories.values():
                if (repo.get("repository_name") == repository_name and 
                    repo.get("owner_id") == owner_id and
                    repo.get("owner_type") == owner_type):
                    return json.dumps({
                        "success": False,
                        "error": f"Repository '{repository_name}' already exists for this owner"
                    })
            
            new_repo_id = generate_id(repositories)
            
            new_repo = {
                "repository_id": new_repo_id,
                "repository_name": repository_name,
                "owner_type": owner_type,
                "owner_id": owner_id,
                "description": description,
                "visibility": visibility if visibility else "private",
                "default_branch": default_branch if default_branch else "main",
                "is_fork": False,
                "parent_repository_id": None,
                "is_archived": bool(is_archived) if is_archived is not None else False,
                "is_template": bool(is_template) if is_template is not None else False,
                "stars_count": stars_count if stars_count is not None else 0,
                "forks_count": forks_count if forks_count is not None else 0,
                "license_type": license_type,
                "created_at": timestamp,
                "updated_at": timestamp,
                "pushed_at": None
            }
            
            repositories[new_repo_id] = new_repo
            
            return json.dumps({
                "success": True,
                "action": "create",
                "repository_id": new_repo_id,
                "repository_data": new_repo
            })
        
        elif action == "update":
            # repository_id is required for update
            if not repository_id:
                return json.dumps({
                    "success": False,
                    "error": "repository_id is required for update action"
                })
            
            if repository_id not in repositories:
                return json.dumps({
                    "success": False,
                    "error": f"Repository with ID '{repository_id}' not found"
                })
            
            repo = repositories[repository_id]
            
            # Validate owner exists if being updated
            if owner_type == "user":
                if owner_id not in users:
                    return json.dumps({
                        "success": False,
                        "error": f"User with ID '{owner_id}' not found"
                    })
            elif owner_type == "organization":
                if owner_id not in organizations:
                    return json.dumps({
                        "success": False,
                        "error": f"Organization with ID '{owner_id}' not found"
                    })
            else:
                return json.dumps({
                    "success": False,
                    "error": f"Invalid owner_type '{owner_type}'. Must be 'user' or 'organization'"
                })
            
            # Validate visibility if provided
            if visibility and visibility not in ["public", "private", "internal"]:
                return json.dumps({
                    "success": False,
                    "error": f"Invalid visibility '{visibility}'. Must be 'public', 'private', or 'internal'"
                })
            
            # Validate license_type if provided
            if license_type and license_type not in ["MIT", "Apache-2.0", "GPL-3.0", "BSD-3-Clause", "unlicensed", "other"]:
                return json.dumps({
                    "success": False,
                    "error": f"Invalid license_type '{license_type}'. Must be one of: 'MIT', 'Apache-2.0', 'GPL-3.0', 'BSD-3-Clause', 'unlicensed', 'other'"
                })
            
            # Check for duplicate repository name if name/owner is being changed
            if (repository_name != repo.get("repository_name") or 
                owner_id != repo.get("owner_id") or 
                owner_type != repo.get("owner_type")):
                for other_repo_id, other_repo in repositories.items():
                    if other_repo_id != repository_id:
                        if (other_repo.get("repository_name") == repository_name and 
                            other_repo.get("owner_id") == owner_id and
                            other_repo.get("owner_type") == owner_type):
                            return json.dumps({
                                "success": False,
                                "error": f"Repository '{repository_name}' already exists for this owner"
                            })
            
            # Update fields
            repo["repository_name"] = repository_name
            repo["owner_type"] = owner_type
            repo["owner_id"] = owner_id
            if description is not None:
                repo["description"] = description
            if visibility is not None:
                repo["visibility"] = visibility
            if default_branch is not None:
                repo["default_branch"] = default_branch
            if is_template is not None:
                repo["is_template"] = is_template
            if license_type is not None:
                repo["license_type"] = license_type
            if is_archived is not None:
                repo["is_archived"] = is_archived
            if forks_count is not None:
                repo["forks_count"] = forks_count
            if stars_count is not None:
                repo["stars_count"] = stars_count
            
            repo["updated_at"] = timestamp
            
            return json.dumps({
                "success": True,
                "action": "update",
                "repository_id": repository_id,
                "repository_data": repo
            })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "upsert_repository",
                "description": "Creates or updates a repository.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "action": {
                            "type": "string",
                            "description": "Action to perform. Allowed values: 'create', 'update' (required)",
                            "enum": ["create", "update"]
                        },
                        "access_token": {
                            "type": "string",
                            "description": "Access token for authentication (required)"
                        },
                        "repository_name": {
                            "type": "string",
                            "description": "Name of the repository (required)"
                        },
                        "owner_type": {
                            "type": "string",
                            "description": "Type of owner. Allowed values: 'user', 'organization' (required)",
                            "enum": ["user", "organization"]
                        },
                        "owner_id": {
                            "type": "string",
                            "description": "ID of the owner (user_id or organization_id) (required)"
                        },
                        "description": {
                            "type": "string",
                            "description": "Repository description (optional)"
                        },
                        "visibility": {
                            "type": "string",
                            "description": "Repository visibility. Allowed values: 'public', 'private', 'internal' (optional, defaults to 'private' for create)",
                            "enum": ["public", "private", "internal"]
                        },
                        "default_branch": {
                            "type": "string",
                            "description": "Default branch name (optional, defaults to 'main' for create)"
                        },
                        "is_template": {
                            "type": "boolean",
                            "description": "Whether repository is a template. Allowed values: True, False (optional, defaults to False for create)"
                        },
                        "license_type": {
                            "type": "string",
                            "description": "Repository license type. Allowed values: 'MIT', 'Apache-2.0', 'GPL-3.0', 'BSD-3-Clause', 'unlicensed', 'other' (optional)",
                            "enum": ["MIT", "Apache-2.0", "GPL-3.0", "BSD-3-Clause", "unlicensed", "other"]
                        },
                        "is_archived": {
                            "type": "boolean",
                            "description": "Whether repository is archived. Allowed values: True, False (optional, defaults to False for create)"
                        },
                        "repository_id": {
                            "type": "string",
                            "description": "Repository ID (required for update action)"
                        },
                        "forks_count": {
                            "type": "integer",
                            "description": "Number of forks (optional)"
                        },
                        "stars_count": {
                            "type": "integer",
                            "description": "Number of stars (optional)"
                        }
                    },
                    "required": ["action", "access_token", "repository_name", "owner_type", "owner_id"]
                }
            }
        }
